{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abd91a44-50de-4ab2-98d9-d3f4d6655fd8",
   "metadata": {},
   "source": [
    "# Driver Distraction Detection Algorithm using YOLOv5 (w, w/o Attention Model)\n",
    "\n",
    "ToC:\n",
    "\n",
    "0. Environment\n",
    "    0. Setup and modify files\n",
    "1. YOLOv5 Only\n",
    "    0. Setup\n",
    "    1. Training\n",
    "    2. Validation\n",
    "2. YOLOv5 + SENet\n",
    "    0. Setup\n",
    "    1. Training\n",
    "    2. Validation\n",
    "3. YOLOv5 + ECANet\n",
    "    0. Setup\n",
    "    1. Training\n",
    "    2. Validation\n",
    "4. YOLOv5 + SENet + ECANet\n",
    "    0. Setup\n",
    "    1. Training\n",
    "    2. Validation\n",
    "5. YOLOv5 Only w/o Augmentations (Benchmark)\n",
    "    0. Setup\n",
    "    1. Training\n",
    "    2. Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfbb910-0a34-4510-8a39-d0a55a67d7bb",
   "metadata": {},
   "source": [
    "## 0.0 Setup and modify files\n",
    "### 0.1 Environment Setup\n",
    "\n",
    "1. Download YOLOv5 and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de68dd44-3dbe-4b36-8146-bf56eac8a490",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-10T04:38:16.684301Z",
     "iopub.status.busy": "2023-05-10T04:38:16.683889Z",
     "iopub.status.idle": "2023-05-10T04:39:44.447489Z",
     "shell.execute_reply": "2023-05-10T04:39:44.446013Z",
     "shell.execute_reply.started": "2023-05-10T04:38:16.684269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Downloading roboflow-1.0.8-py3-none-any.whl (56 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from roboflow) (5.4.1)\n",
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.9/dist-packages (from roboflow) (4.64.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from roboflow) (2.28.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from roboflow) (1.23.4)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.9/dist-packages (from roboflow) (1.4.4)\n",
      "Collecting pyparsing==2.4.7\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.9/dist-packages (from roboflow) (4.6.0.66)\n",
      "Collecting idna==2.10\n",
      "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests-toolbelt in /usr/local/lib/python3.9/dist-packages (from roboflow) (0.10.1)\n",
      "Collecting chardet==4.0.0\n",
      "  Downloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting certifi==2022.12.7\n",
      "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cycler==0.10.0\n",
      "  Downloading cycler-0.10.0-py2.py3-none-any.whl (6.5 kB)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from roboflow) (3.6.1)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from roboflow) (9.2.0)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from roboflow) (2.8.2)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from roboflow) (1.14.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.9/dist-packages (from roboflow) (1.26.14)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->roboflow) (4.38.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->roboflow) (1.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->roboflow) (23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->roboflow) (2.1.1)\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9656 sha256=5a5bebf4019d94114ce811147882298cf01b700a75fc1165cec5a9b7bdd280a6\n",
      "  Stored in directory: /root/.cache/pip/wheels/ba/78/fb/e0c24a9e73d7483b073d15b7e05f43f3fc2ac75eff6899c7aa\n",
      "Successfully built wget\n",
      "Installing collected packages: wget, python-dotenv, pyparsing, idna, cycler, chardet, certifi, roboflow\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.9\n",
      "    Uninstalling pyparsing-3.0.9:\n",
      "      Successfully uninstalled pyparsing-3.0.9\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 2.8\n",
      "    Uninstalling idna-2.8:\n",
      "      Successfully uninstalled idna-2.8\n",
      "  Attempting uninstall: cycler\n",
      "    Found existing installation: cycler 0.11.0\n",
      "    Uninstalling cycler-0.11.0:\n",
      "      Successfully uninstalled cycler-0.11.0\n",
      "  Attempting uninstall: chardet\n",
      "    Found existing installation: chardet 3.0.4\n",
      "    Uninstalling chardet-3.0.4:\n",
      "      Successfully uninstalled chardet-3.0.4\n",
      "  Attempting uninstall: certifi\n",
      "    Found existing installation: certifi 2019.11.28\n",
      "    Uninstalling certifi-2019.11.28:\n",
      "      Successfully uninstalled certifi-2019.11.28\n",
      "Successfully installed certifi-2022.12.7 chardet-4.0.0 cycler-0.10.0 idna-2.10 pyparsing-2.4.7 python-dotenv-1.0.0 roboflow-1.0.8 wget-3.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mmkdir: cannot create directory ‚Äò/notebooks/datasets‚Äô: File exists\n",
      "/notebooks/datasets\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Downloading Dataset Version Zip in Driver-Distraction-Detection-1 to folder: 8% [24567808 / 293628018] bytes"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Driver-Distraction-Detection-1 to folder: 20% [59293696 / 293628018] bytes"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Driver-Distraction-Detection-1 to folder: 32% [94699520 / 293628018] bytes"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Driver-Distraction-Detection-1 to folder: 47% [140181504 / 293628018] bytes"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Driver-Distraction-Detection-1 to folder: 61% [180002816 / 293628018] bytes"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Driver-Distraction-Detection-1 to folder: 73% [215547904 / 293628018] bytes"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Driver-Distraction-Detection-1 to folder: 85% [249856000 / 293628018] bytes"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in Driver-Distraction-Detection-1 to folder: 97% [285204480 / 293628018] bytes"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "Extracting Dataset Version Zip to Driver-Distraction-Detection-1 in folder:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 25811/25811 [00:52<00:00, 493.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/datasets/Driver-Distraction-Detection-1\n",
      "Requirement already satisfied: comet_ml in /usr/local/lib/python3.9/dist-packages (3.33.1)\n",
      "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.9/dist-packages (from comet_ml) (4.17.3)\n",
      "Requirement already satisfied: everett[ini]<3.2.0,>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from comet_ml) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from comet_ml) (1.26.14)\n",
      "Requirement already satisfied: semantic-version>=2.8.0 in /usr/local/lib/python3.9/dist-packages (from comet_ml) (2.10.0)\n",
      "Requirement already satisfied: websocket-client<1.4.0,>=0.55.0 in /usr/local/lib/python3.9/dist-packages (from comet_ml) (0.57.0)\n",
      "Requirement already satisfied: python-box<7.0.0 in /usr/local/lib/python3.9/dist-packages (from comet_ml) (6.1.0)\n",
      "Requirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from comet_ml) (0.10.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from comet_ml) (1.14.0)\n",
      "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.9/dist-packages (from comet_ml) (3.0.3)\n",
      "Requirement already satisfied: dulwich!=0.20.33,>=0.20.6 in /usr/local/lib/python3.9/dist-packages (from comet_ml) (0.21.5)\n",
      "Requirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.9/dist-packages (from comet_ml) (13.3.5)\n",
      "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.9/dist-packages (from comet_ml) (2.28.2)\n",
      "Requirement already satisfied: sentry-sdk>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from comet_ml) (1.14.0)\n",
      "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.9/dist-packages (from comet_ml) (1.14.1)\n",
      "Requirement already satisfied: simplejson in /usr/local/lib/python3.9/dist-packages (from comet_ml) (3.19.1)\n",
      "Requirement already satisfied: configobj in /usr/local/lib/python3.9/dist-packages (from everett[ini]<3.2.0,>=1.0.1->comet_ml) (5.0.8)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.19.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (18.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.18.4->comet_ml) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.18.4->comet_ml) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests>=2.18.4->comet_ml) (2.1.1)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from rich>=13.3.2->comet_ml) (2.14.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /usr/local/lib/python3.9/dist-packages (from rich>=13.3.2->comet_ml) (2.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=13.3.2->comet_ml) (0.1.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%export` not found.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5\n",
    "%cd /notebooks/yolov5\n",
    "%pip install -qr requirements.txt\n",
    "\n",
    "import torch\n",
    "import utils\n",
    "\n",
    "!pip install roboflow\n",
    "\n",
    "%mkdir /notebooks/datasets\n",
    "%cd /notebooks/datasets\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"8CMZTXltcjnnKhuvAKuJ\")\n",
    "project = rf.workspace(\"fyp-cli-v01\").project(\"driver-distraction-detection\")\n",
    "dataset = project.version(1).download(\"folder\")\n",
    "\n",
    "%cd /notebooks/datasets/Driver-Distraction-Detection-1\n",
    "%mv valid val\n",
    "\n",
    "%cd /notebooks/yolov5/\n",
    "display = utils.notebook_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8d2cf36-ab4a-4f0d-ae51-33b6f07b8e89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T15:50:51.042716Z",
     "iopub.status.busy": "2023-05-31T15:50:51.042129Z",
     "iopub.status.idle": "2023-05-31T15:50:53.446519Z",
     "shell.execute_reply": "2023-05-31T15:50:53.445798Z",
     "shell.execute_reply.started": "2023-05-31T15:50:51.042686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.9/dist-packages (0.11.4)\n",
      "Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.12.1+cu116)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (1.23.4)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from torchmetrics) (23.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.8.1->torchmetrics) (4.4.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m/notebooks/yolov5\n"
     ]
    }
   ],
   "source": [
    "!pip install torchmetrics\n",
    "%cd /notebooks/yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ab626c-ec45-4e97-9f24-62def74c7c7b",
   "metadata": {},
   "source": [
    "### 0.2 Modify files\n",
    "\n",
    "Task list:\n",
    "1. Created and written yolov5s-cls.yaml in models directory.\n",
    "2. Modified classify/train.py and models/yolo.py\n",
    "\n",
    "Reference:\n",
    "https://github.com/ultralytics/yolov5/pull/9743/files#diff-2cd118cbb69c9ca7b5544f4187b11335fc3addbaf2c3c5bb45435cac648c957b\n",
    "(Pull request to implement --cfg argument in later versions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f371fab3-5930-437f-ba8d-8f1211dfbdc8",
   "metadata": {},
   "source": [
    "## 1.0 3DA using YOLOv5 Only\n",
    "\n",
    "### 1.1 Training (E = 10, 25, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed6899d1-cbba-4268-b563-f23caad04d57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-10T07:36:02.913859Z",
     "iopub.status.busy": "2023-05-10T07:36:02.913193Z",
     "iopub.status.idle": "2023-05-10T07:52:23.443953Z",
     "shell.execute_reply": "2023-05-10T07:52:23.443130Z",
     "shell.execute_reply.started": "2023-05-10T07:36:02.913828Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-cls.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=10, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 1 commit. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-cls summary: 216 layers, 25284490 parameters, 25284490 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 61 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp29\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 10 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/10     2.42G        2.29         2.3       0.122       0.614: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/10      2.9G         2.2        2.09       0.253       0.785: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/10      2.9G        1.89         1.6       0.498       0.921: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/10      2.9G        1.54        1.51       0.587       0.949: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/10      2.9G        1.29        1.08       0.763       0.987: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/10      2.9G        1.09       0.973       0.826       0.987: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/10      2.9G       0.942       0.816       0.901       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/10      2.9G        0.82       0.757       0.924       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/10      2.9G       0.731       0.704       0.941       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/10      2.9G       0.661        0.67       0.953       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (0.257 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp29\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp29/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp29/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1\n",
      "Export:          python export.py --weights runs/train-cls/exp29/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp29/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train.py --model yolov5s-cls.pt --cfg models/yolov5s-cls.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 10 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "25522b8a-0276-4ba4-a881-37014aabf45f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-08T14:26:00.146489Z",
     "iopub.status.busy": "2023-05-08T14:26:00.146100Z",
     "iopub.status.idle": "2023-05-08T16:10:10.412509Z",
     "shell.execute_reply": "2023-05-08T16:10:10.411060Z",
     "shell.execute_reply.started": "2023-05-08T14:26:00.146458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-cls.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=25, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 ‚úÖ\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro P5000, 16279MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-cls summary: 216 layers, 25284490 parameters, 25284490 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 61 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp3\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 25 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/25      2.3G        2.29         2.3       0.135       0.609: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/25     2.56G        2.17           2        0.29       0.816: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/25     2.56G        1.86        1.66       0.479       0.924: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/25     2.56G         1.5        1.29       0.663       0.971: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/25     2.56G        1.23        1.08       0.776       0.985: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/25     2.56G        1.05       0.867       0.876       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/25     2.56G       0.928       0.813       0.903       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/25     2.56G       0.835       0.741       0.931       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/25     2.56G       0.772       0.708       0.948       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/25     2.56G       0.725       0.679       0.954       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     11/25     2.56G        0.69       0.666       0.959       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     12/25     2.56G       0.658       0.648       0.964       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     13/25     2.56G       0.637       0.637       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     14/25     2.56G       0.616       0.626       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     15/25     2.56G         0.6       0.622       0.974       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     16/25     2.56G       0.585        0.61       0.976       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     17/25     2.56G       0.569       0.606       0.976       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     18/25     2.56G       0.561       0.601       0.976       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     19/25     2.56G       0.552       0.595       0.976       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     20/25     2.56G       0.545       0.591       0.977       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     21/25     2.56G       0.538       0.588       0.977       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     22/25     2.56G        0.53       0.586       0.978       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     23/25     2.56G       0.525       0.584       0.979       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     24/25     2.56G        0.52       0.584       0.979       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     25/25     2.56G       0.516       0.583       0.979       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (1.719 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp3\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp3/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp3/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1\n",
      "Export:          python export.py --weights runs/train-cls/exp3/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp3/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train.py --model yolov5s-cls.pt --cfg models/yolov5s-cls.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 25 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "86a069d9-cc42-4e3b-a09a-1a9826e99ee4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-10T07:52:23.445669Z",
     "iopub.status.busy": "2023-05-10T07:52:23.445388Z",
     "iopub.status.idle": "2023-05-10T09:11:05.437950Z",
     "shell.execute_reply": "2023-05-10T09:11:05.437144Z",
     "shell.execute_reply.started": "2023-05-10T07:52:23.445631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-cls.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=50, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 1 commit. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-cls summary: 216 layers, 25284490 parameters, 25284490 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 61 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp30\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 50 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/50     2.42G        2.29         2.3       0.122       0.614: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/50      2.9G        2.21        2.04       0.238       0.794: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/50      2.9G        1.99        1.93       0.338       0.846: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/50      2.9G        1.83        1.74        0.44       0.901: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/50      2.9G        1.55         1.3       0.644       0.967: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/50      2.9G        1.26        1.05       0.795       0.991: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/50      2.9G         1.1       0.902       0.857       0.992: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/50      2.9G       0.977       0.811       0.903       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/50      2.9G       0.896       0.771       0.914       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/50      2.9G       0.839        0.72        0.94       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     11/50      2.9G       0.794       0.704       0.945       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     12/50      2.9G       0.749       0.692       0.945       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     13/50      2.9G       0.724       0.669       0.956       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     14/50      2.9G       0.692       0.659       0.958       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     15/50      2.9G       0.673       0.653       0.957       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     16/50      2.9G       0.655       0.646        0.96       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     17/50      2.9G       0.635       0.637       0.963       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     18/50      2.9G       0.622       0.634       0.964       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     19/50      2.9G       0.611       0.626       0.967       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     20/50      2.9G       0.598        0.62       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     21/50      2.9G        0.59       0.616       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     22/50      2.9G       0.584       0.613       0.971       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     23/50      2.9G       0.574       0.611       0.971       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     24/50      2.9G        0.57       0.609       0.971       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     25/50      2.9G       0.562       0.607        0.97       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     26/50      2.9G       0.561       0.606        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     27/50      2.9G       0.552       0.605        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     28/50      2.9G       0.554       0.604        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     29/50      2.9G       0.541       0.605       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     30/50      2.9G       0.548       0.608       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     31/50      2.9G       0.542       0.612       0.964       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     32/50      2.9G       0.534       0.618       0.962       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     33/50      2.9G       0.539       0.628       0.958       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     34/50      2.9G       0.528       0.641       0.954       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     35/50      2.9G       0.529       0.662       0.948       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     36/50      2.9G       0.525       0.686       0.939       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     37/50      2.9G       0.526       0.717       0.932       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     38/50      2.9G       0.519       0.757        0.92       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     39/50      2.9G       0.523        0.81        0.89       0.993: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     40/50      2.9G       0.521       0.862       0.872       0.992: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     41/50      2.9G       0.515       0.927        0.84       0.991: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     42/50      2.9G       0.514           1       0.796       0.988: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     43/50      2.9G       0.515        1.08       0.752       0.985: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     44/50      2.9G       0.511        1.17       0.705       0.983: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     45/50      2.9G       0.511        1.27       0.655       0.982: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     46/50      2.9G       0.512        1.35       0.604       0.979: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     47/50      2.9G       0.508        1.44        0.55       0.975: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     48/50      2.9G       0.507        1.53       0.508       0.967: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     49/50      2.9G       0.506        1.61       0.468       0.961: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     50/50      2.9G       0.506        1.68       0.434       0.952: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (1.297 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp30\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp30/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp30/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1\n",
      "Export:          python export.py --weights runs/train-cls/exp30/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp30/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train.py --model yolov5s-cls.pt --cfg models/yolov5s-cls.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 50 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ff23ad-b423-4ba3-8fd5-19c1f3af3a27",
   "metadata": {},
   "source": [
    "### 1.2 Validation (E = 10, 25, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2f10da4-617e-46c5-903f-9e99042757ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T06:46:27.511513Z",
     "iopub.status.busy": "2023-05-11T06:46:27.511115Z",
     "iopub.status.idle": "2023-05-11T06:46:40.987359Z",
     "shell.execute_reply": "2023-05-11T06:46:40.986327Z",
     "shell.execute_reply.started": "2023-05-11T06:46:27.511472Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp29/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-cls summary: 156 layers, 25267786 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:04<00:00,  3.30it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.953       0.997\n",
      "                drinking         182       0.934       0.995\n",
      "         hair and makeup         173       0.792       0.988\n",
      "     operating the radio         224       0.982           1\n",
      "         reaching behind         189       0.947           1\n",
      "            safe driving         205       0.941       0.995\n",
      "talking on the phone - left         218           1           1\n",
      "talking on the phone - right         209       0.986       0.995\n",
      "    talking to passenger         182       0.945       0.995\n",
      "          texting - left         209       0.971           1\n",
      "         texting - right         193       0.995           1\n",
      "Accuracy: 0.9493480920791626 | Precision: 0.9512302875518799 | Recall: 0.9493480920791626\n",
      "F1-Score: 0.9496405720710754 | Mean Average Precision: 0.9840421676635742\n",
      "Confusion Matrix:\n",
      "tensor([[170,   4,   0,   0,   0,   0,   2,   1,   0,   5],\n",
      "        [  9, 137,   5,   3,   1,   2,   9,   6,   1,   0],\n",
      "        [  0,   0, 220,   0,   2,   0,   0,   2,   0,   0],\n",
      "        [  0,   4,   4, 179,   0,   0,   0,   2,   0,   0],\n",
      "        [  1,   4,   2,   0, 193,   0,   0,   5,   0,   0],\n",
      "        [  0,   0,   0,   0,   0, 218,   0,   0,   0,   0],\n",
      "        [  1,   0,   0,   0,   0,   0, 206,   2,   0,   0],\n",
      "        [  0,   1,   1,   2,   3,   0,   1, 172,   1,   1],\n",
      "        [  0,   0,   1,   0,   1,   1,   0,   3, 203,   0],\n",
      "        [  0,   0,   0,   0,   1,   0,   0,   0,   0, 192]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1890,    94, 17762,    94,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 2.0ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp62\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp29/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b394342-d0f5-4d05-980c-70b7d0718c3b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T06:46:40.989258Z",
     "iopub.status.busy": "2023-05-11T06:46:40.988996Z",
     "iopub.status.idle": "2023-05-11T06:46:54.921070Z",
     "shell.execute_reply": "2023-05-11T06:46:54.920261Z",
     "shell.execute_reply.started": "2023-05-11T06:46:40.989232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp3/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-cls summary: 156 layers, 25267786 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:04<00:00,  3.31it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.979       0.999\n",
      "                drinking         182       0.984           1\n",
      "         hair and makeup         173       0.896       0.988\n",
      "     operating the radio         224       0.982           1\n",
      "         reaching behind         189       0.995           1\n",
      "            safe driving         205        0.99           1\n",
      "talking on the phone - left         218           1           1\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182       0.956           1\n",
      "          texting - left         209        0.99           1\n",
      "         texting - right         193        0.99           1\n",
      "Accuracy: 0.9777893424034119 | Precision: 0.9794467687606812 | Recall: 0.9777893424034119\n",
      "F1-Score: 0.9783528447151184 | Mean Average Precision: 0.9955357909202576\n",
      "Confusion Matrix:\n",
      "tensor([[179,   2,   0,   0,   0,   0,   0,   0,   0,   1],\n",
      "        [  5, 155,   2,   1,   2,   2,   4,   1,   1,   0],\n",
      "        [  0,   0, 220,   0,   2,   0,   0,   2,   0,   0],\n",
      "        [  0,   0,   1, 188,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,   0,   0,   0, 203,   0,   0,   1,   0,   0],\n",
      "        [  0,   0,   0,   0,   0, 218,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0, 208,   0,   0,   1],\n",
      "        [  0,   1,   1,   0,   4,   0,   1, 174,   1,   0],\n",
      "        [  0,   0,   0,   0,   1,   1,   0,   0, 207,   0],\n",
      "        [  0,   0,   0,   0,   1,   0,   1,   0,   0, 191]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1943,    41, 17815,    41,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 2.0ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp63\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp3/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "449fa56a-2462-4463-a9e9-bfcf0b89607b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T06:46:54.922569Z",
     "iopub.status.busy": "2023-05-11T06:46:54.922322Z",
     "iopub.status.idle": "2023-05-11T06:47:08.926997Z",
     "shell.execute_reply": "2023-05-11T06:47:08.925942Z",
     "shell.execute_reply.started": "2023-05-11T06:46:54.922544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp30/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-cls summary: 156 layers, 25267786 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:04<00:00,  3.21it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.971       0.999\n",
      "                drinking         182       0.967           1\n",
      "         hair and makeup         173        0.85       0.994\n",
      "     operating the radio         224       0.987           1\n",
      "         reaching behind         189       0.984           1\n",
      "            safe driving         205        0.98       0.995\n",
      "talking on the phone - left         218           1           1\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182       0.945           1\n",
      "          texting - left         209        0.99           1\n",
      "         texting - right         193        0.99           1\n",
      "Accuracy: 0.9688304662704468 | Precision: 0.970193088054657 | Recall: 0.9688304662704468\n",
      "F1-Score: 0.9691617488861084 | Mean Average Precision: 0.9944543242454529\n",
      "Confusion Matrix:\n",
      "tensor([[176,   2,   0,   0,   0,   0,   0,   1,   0,   3],\n",
      "        [  6, 147,   2,   3,   3,   1,   5,   6,   0,   0],\n",
      "        [  0,   0, 221,   0,   1,   0,   0,   2,   0,   0],\n",
      "        [  0,   1,   1, 186,   0,   0,   0,   1,   0,   0],\n",
      "        [  1,   2,   0,   0, 201,   0,   0,   1,   0,   0],\n",
      "        [  0,   0,   0,   0,   0, 218,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0, 208,   0,   0,   1],\n",
      "        [  0,   2,   0,   1,   4,   0,   1, 172,   1,   1],\n",
      "        [  0,   0,   1,   0,   1,   0,   0,   0, 207,   0],\n",
      "        [  0,   0,   0,   0,   1,   0,   0,   1,   0, 191]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1927,    57, 17799,    57,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 2.0ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp64\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp30/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5671a75-240f-4342-b058-6d1a212746cc",
   "metadata": {},
   "source": [
    "## 2.0 3DA using YOLOv5 + SENet\n",
    "\n",
    "### Setup:\n",
    "\n",
    "Task list:\n",
    "1. Created and written yolov5s-senet.yaml in models directory.\n",
    "2. Modified common.py by adding SENet's module code.\n",
    "\n",
    "Reference: \n",
    "1. https://medium.com/@fletcherpearmaine/senet-and-co-ordinatte-attention-modules-and-their-integration-into-the-yolov5-object-detection-34bc66a3f234\n",
    "2. https://github.com/mohenghui/yolov5_attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34aec59a-cb4a-4002-8b9c-bb42feb254f3",
   "metadata": {},
   "source": [
    "### 2.1 Training (E = 10, 25, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c732322c-1bee-4b7b-a304-f23f7e2c5935",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T03:46:32.248987Z",
     "iopub.status.busy": "2023-05-09T03:46:32.248207Z",
     "iopub.status.idle": "2023-05-09T04:30:14.692742Z",
     "shell.execute_reply": "2023-05-09T04:30:14.691744Z",
     "shell.execute_reply.started": "2023-05-09T03:46:32.248959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-senet.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=10, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "remote: Enumerating objects: 6, done.\u001b[K\n",
      "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
      "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
      "remote: Total 6 (delta 1), reused 1 (delta 1), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (6/6), 26.94 KiB | 1.22 MiB/s, done.\n",
      "From https://github.com/ultralytics/yolov5\n",
      "   c3e4e94..016e046  master     -> origin/master\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 1 commit. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro P5000, 16279MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1      2048  models.common.SENet                     [1024, 1024]                  \n",
      " 10                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-senet summary: 223 layers, 25286538 parameters, 25286538 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 63 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp8\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 10 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/10      2.3G        2.29        7.96        0.11       0.492: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/10     2.56G        2.08        1.93       0.311        0.85: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/10     2.56G        1.83        1.52       0.527       0.943: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/10     2.56G        1.47        1.22       0.697       0.982: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/10     2.56G         1.2        1.01       0.795       0.993: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/10     2.56G        1.02       0.933       0.842       0.989: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/10     2.56G        0.89       0.797       0.909       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/10     2.56G       0.784       0.714       0.935       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/10     2.56G       0.704        0.68       0.951       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/10     2.56G        0.64       0.654       0.962       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (0.713 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp8\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp8/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp8/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1\n",
      "Export:          python export.py --weights runs/train-cls/exp8/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp8/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train.py --model yolov5s-cls.pt --cfg models/yolov5s-senet.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 10 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7215dd73-5d83-4669-808d-62a777eea649",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T06:05:57.734434Z",
     "iopub.status.busy": "2023-05-09T06:05:57.734097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-senet.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=25, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 1 commit. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro P5000, 16279MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1      2048  models.common.SENet                     [1024, 1024]                  \n",
      " 10                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-senet summary: 223 layers, 25286538 parameters, 25286538 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 63 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp11\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 25 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/25      2.3G        2.29        7.96        0.11       0.492: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/25     2.56G        2.12        2.13       0.221        0.76: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/25     2.56G        1.92        1.76       0.432       0.883: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/25     2.56G        1.57        1.26       0.671       0.968: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/25     2.56G        1.27         1.1       0.755       0.985: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/25     2.56G         1.1       0.895       0.861       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/25     2.56G       0.988       0.858        0.88       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/25     2.56G       0.893       0.752       0.923       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/25     2.56G        0.83       0.733       0.926       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/25     2.56G       0.781         0.7       0.943       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     11/25     2.56G       0.738       0.678        0.95       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     12/25     2.56G       0.713       0.661       0.961       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     13/25     2.56G       0.687       0.656       0.961       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     14/25     2.56G       0.657       0.642       0.964       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     15/25     2.56G       0.637        0.63        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     16/25     2.56G       0.619       0.624       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     17/25     2.56G       0.601       0.617        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     18/25     2.56G       0.584       0.611       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     19/25     2.56G       0.571       0.605       0.972       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     20/25     2.56G       0.561         0.6       0.973       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     21/25     2.56G        0.55       0.597       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     22/25     2.56G       0.541       0.593       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     23/25     2.56G       0.532       0.591       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     24/25     2.56G       0.527        0.59       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     25/25     2.56G       0.522                                    :  88%|‚ñà‚ñà‚ñà‚ñà‚ñà"
     ]
    }
   ],
   "source": [
    " !python classify/train.py --model yolov5s-cls.pt --cfg models/yolov5s-senet.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 25 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28f6282d-53e0-4977-981e-6fb3ab762f45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-10T09:11:05.439346Z",
     "iopub.status.busy": "2023-05-10T09:11:05.439046Z",
     "iopub.status.idle": "2023-05-10T10:30:31.297657Z",
     "shell.execute_reply": "2023-05-10T10:30:31.296866Z",
     "shell.execute_reply.started": "2023-05-10T09:11:05.439310Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-senet.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=50, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 1 commit. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1      2048  models.common.SENet                     [1024, 1024]                  \n",
      " 10                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-senet summary: 223 layers, 25286538 parameters, 25286538 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 63 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp31\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 50 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/50     2.46G        2.29        2.46       0.118       0.585: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/50     2.93G         2.1        1.88       0.334       0.863: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/50     2.93G        1.75        1.59       0.515       0.921: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/50     2.93G        1.45        1.21       0.707        0.98: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/50     2.93G        1.22         1.1       0.782       0.986: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/50     2.93G        1.07       0.923        0.84       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/50     2.93G       0.982       0.854       0.879       0.993: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/50     2.93G       0.899       0.778       0.917       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/50     2.93G       0.855       0.744       0.926       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/50     2.93G       0.806       0.711       0.945       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     11/50     2.93G       0.767        0.69       0.952       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     12/50     2.93G       0.739       0.679       0.958       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     13/50     2.93G       0.713       0.669       0.959       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     14/50     2.93G        0.69       0.658       0.962       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     15/50     2.93G        0.67       0.655       0.965       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     16/50     2.93G       0.655        0.65       0.962       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     17/50     2.93G       0.635       0.639       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     18/50     2.93G       0.622       0.636       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     19/50     2.93G       0.617       0.633        0.97       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     20/50     2.93G       0.602       0.628       0.971       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     21/50     2.93G       0.591       0.624        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     22/50     2.93G       0.586       0.622        0.97       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     23/50     2.93G       0.575        0.62       0.971       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     24/50     2.93G       0.571       0.619       0.971       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     25/50     2.93G       0.566       0.617       0.971       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     26/50     2.93G       0.561       0.616       0.971       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     27/50     2.93G       0.558       0.617       0.971       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     28/50     2.93G        0.55       0.619        0.97       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     29/50     2.93G       0.551       0.622       0.968       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     30/50     2.93G       0.542       0.628       0.966       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     31/50     2.93G       0.539       0.638       0.962       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     32/50     2.93G       0.544       0.653       0.956       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     33/50     2.93G       0.532       0.675       0.946       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     34/50     2.93G       0.534       0.707       0.931       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     35/50     2.93G       0.526       0.754       0.904       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     36/50     2.93G       0.529       0.814       0.872       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     37/50     2.93G       0.522       0.897       0.814       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     38/50     2.93G       0.524       0.994       0.754       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     39/50     2.93G        0.52        1.11       0.698       0.991: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     40/50     2.93G        0.52        1.24       0.635       0.988: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     41/50     2.93G       0.519        1.39       0.558       0.981: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     42/50     2.93G       0.514        1.54       0.487       0.968: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     43/50     2.93G       0.512         1.7       0.417       0.957: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     44/50     2.93G       0.512        1.88       0.322       0.935: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     45/50     2.93G       0.511        2.05       0.259       0.911: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     46/50     2.93G       0.509         2.2       0.215       0.881: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     47/50     2.93G       0.509        2.34       0.179       0.858: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     48/50     2.93G       0.507        2.46       0.154       0.825: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     49/50     2.93G       0.506        2.56       0.139       0.795: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     50/50     2.93G       0.505        2.64        0.13       0.762: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (1.309 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp31\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp31/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp31/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1\n",
      "Export:          python export.py --weights runs/train-cls/exp31/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp31/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train.py --model yolov5s-cls.pt --cfg models/yolov5s-senet.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 50 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145a91dc-daaf-4cae-a214-ed56d9ff334e",
   "metadata": {},
   "source": [
    "### 2.2 Validation (E = 10, 25, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40425c73-7274-4d95-a2ff-c6ec3136790d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T06:51:08.136340Z",
     "iopub.status.busy": "2023-05-11T06:51:08.135574Z",
     "iopub.status.idle": "2023-05-11T06:51:22.282020Z",
     "shell.execute_reply": "2023-05-11T06:51:22.281251Z",
     "shell.execute_reply.started": "2023-05-11T06:51:08.136304Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp8/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-senet summary: 163 layers, 25269834 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:05<00:00,  3.16it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.962       0.997\n",
      "                drinking         182       0.956           1\n",
      "         hair and makeup         173       0.827       0.977\n",
      "     operating the radio         224       0.982           1\n",
      "         reaching behind         189       0.984           1\n",
      "            safe driving         205       0.966       0.995\n",
      "talking on the phone - left         218           1           1\n",
      "talking on the phone - right         209       0.986           1\n",
      "    talking to passenger         182       0.918       0.995\n",
      "          texting - left         209       0.981           1\n",
      "         texting - right         193        0.99           1\n",
      "Accuracy: 0.9588483572006226 | Precision: 0.9604007005691528 | Recall: 0.9588483572006226\n",
      "F1-Score: 0.9592698812484741 | Mean Average Precision: 0.9859256148338318\n",
      "Confusion Matrix:\n",
      "tensor([[174,   3,   0,   0,   0,   0,   1,   0,   0,   4],\n",
      "        [  7, 143,   2,   4,   3,   4,   6,   4,   0,   0],\n",
      "        [  0,   1, 220,   1,   1,   0,   0,   1,   0,   0],\n",
      "        [  0,   2,   0, 186,   0,   0,   0,   1,   0,   0],\n",
      "        [  0,   1,   3,   0, 198,   0,   0,   3,   0,   0],\n",
      "        [  0,   0,   0,   0,   0, 218,   0,   0,   0,   0],\n",
      "        [  0,   0,   1,   0,   0,   0, 206,   1,   0,   1],\n",
      "        [  0,   5,   2,   2,   5,   0,   1, 167,   0,   0],\n",
      "        [  0,   0,   0,   0,   3,   0,   0,   1, 205,   0],\n",
      "        [  0,   0,   1,   0,   0,   0,   1,   0,   0, 191]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1908,    76, 17780,    76,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 1.9ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp65\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp8/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb4ab1d0-9370-469b-814b-c8e357d5dde6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T06:51:22.284913Z",
     "iopub.status.busy": "2023-05-11T06:51:22.284663Z",
     "iopub.status.idle": "2023-05-11T06:51:35.968531Z",
     "shell.execute_reply": "2023-05-11T06:51:35.967749Z",
     "shell.execute_reply.started": "2023-05-11T06:51:22.284888Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp11/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-senet summary: 163 layers, 25269834 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:04<00:00,  3.28it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.974       0.998\n",
      "                drinking         182       0.967           1\n",
      "         hair and makeup         173        0.89       0.994\n",
      "     operating the radio         224       0.987           1\n",
      "         reaching behind         189       0.989           1\n",
      "            safe driving         205       0.966       0.995\n",
      "talking on the phone - left         218           1           1\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182       0.945       0.995\n",
      "          texting - left         209        0.99       0.995\n",
      "         texting - right         193       0.995           1\n",
      "Accuracy: 0.9724605083465576 | Precision: 0.9736299514770508 | Recall: 0.9724605083465576\n",
      "F1-Score: 0.9728512763977051 | Mean Average Precision: 0.9948558807373047\n",
      "Confusion Matrix:\n",
      "tensor([[176,   1,   1,   0,   2,   1,   0,   0,   0,   1],\n",
      "        [  6, 154,   1,   1,   1,   2,   4,   4,   0,   0],\n",
      "        [  0,   0, 221,   0,   1,   0,   0,   2,   0,   0],\n",
      "        [  0,   0,   0, 187,   0,   0,   0,   2,   0,   0],\n",
      "        [  1,   2,   2,   0, 198,   0,   0,   2,   0,   0],\n",
      "        [  0,   0,   0,   0,   0, 218,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0, 208,   0,   0,   1],\n",
      "        [  0,   2,   0,   1,   4,   0,   1, 172,   0,   2],\n",
      "        [  0,   0,   0,   0,   2,   0,   0,   0, 207,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   1,   0, 192]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1933,    51, 17805,    51,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 2.1ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp66\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp11/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d910a942-a7ec-4c8d-8191-e394936d8b81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T06:51:35.969761Z",
     "iopub.status.busy": "2023-05-11T06:51:35.969505Z",
     "iopub.status.idle": "2023-05-11T06:51:49.918751Z",
     "shell.execute_reply": "2023-05-11T06:51:49.917998Z",
     "shell.execute_reply.started": "2023-05-11T06:51:35.969735Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp31/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-senet summary: 163 layers, 25269834 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:05<00:00,  3.18it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.971       0.998\n",
      "                drinking         182       0.945           1\n",
      "         hair and makeup         173       0.844       0.983\n",
      "     operating the radio         224       0.982           1\n",
      "         reaching behind         189       0.979           1\n",
      "            safe driving         205       0.995           1\n",
      "talking on the phone - left         218           1           1\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182       0.967           1\n",
      "          texting - left         209        0.99       0.995\n",
      "         texting - right         193        0.99           1\n",
      "Accuracy: 0.9687402844429016 | Precision: 0.9704821705818176 | Recall: 0.9687402844429016\n",
      "F1-Score: 0.9692010879516602 | Mean Average Precision: 0.9918497204780579\n",
      "Confusion Matrix:\n",
      "tensor([[172,   6,   0,   0,   0,   0,   0,   1,   0,   3],\n",
      "        [  6, 146,   5,   2,   3,   4,   3,   4,   0,   0],\n",
      "        [  0,   0, 220,   0,   3,   0,   0,   1,   0,   0],\n",
      "        [  0,   1,   0, 185,   0,   0,   0,   3,   0,   0],\n",
      "        [  1,   0,   0,   0, 204,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0, 218,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0, 208,   0,   0,   1],\n",
      "        [  0,   1,   0,   0,   3,   0,   1, 176,   0,   1],\n",
      "        [  0,   0,   0,   0,   2,   0,   0,   0, 207,   0],\n",
      "        [  0,   0,   0,   0,   1,   0,   1,   0,   0, 191]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1927,    57, 17799,    57,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 1.8ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp67\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp31/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fca94d-fd76-4be5-a6c1-e7c6d7ce1b9d",
   "metadata": {},
   "source": [
    "## 3.0 3DA using YOLOv5 + ECA\n",
    "\n",
    "### Setup:\n",
    "\n",
    "Task list:\n",
    "1. Created and written yolov5s-eca.yaml in models directory.\n",
    "2. Modified common.py by adding ECA's module code.\n",
    "\n",
    "Reference: \n",
    "1. https://github.com/mohenghui/yolov5_attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e6f3f2-18b1-4201-bda2-d5dd126a14fb",
   "metadata": {},
   "source": [
    "### 3.1 Training (E = 10, 25, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66037af0-b37f-4bd6-b3a1-bf6b464ada15",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T08:42:50.635468Z",
     "iopub.status.busy": "2023-05-09T08:42:50.634237Z",
     "iopub.status.idle": "2023-05-09T09:26:48.102227Z",
     "shell.execute_reply": "2023-05-09T09:26:48.101263Z",
     "shell.execute_reply.started": "2023-05-09T08:42:50.635429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-eca.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=10, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 1 commit. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro P5000, 16279MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 10                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-eca summary: 220 layers, 25284493 parameters, 25284493 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 62 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp14\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 10 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/10      2.3G        2.31        2.46        0.12        0.52: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/10     2.56G         2.3         2.3       0.101       0.506: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/10     2.56G        2.26        2.15       0.182       0.699: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/10     2.56G        1.99        1.92       0.333       0.838: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/10     2.56G        1.59        1.22       0.678       0.977: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/10     2.56G        1.26        1.04       0.784       0.988: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/10     2.56G        1.07       0.916       0.828       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/10     2.56G       0.929       0.834       0.878       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/10     2.56G       0.813       0.732       0.928       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/10     2.56G       0.715       0.684        0.94       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (0.717 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp14\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp14/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp14/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1\n",
      "Export:          python export.py --weights runs/train-cls/exp14/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp14/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train.py --model yolov5s-cls.pt --cfg models/yolov5s-eca.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 10 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a56976c-c6fe-42af-91d0-246aca47d213",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T13:29:39.584453Z",
     "iopub.status.busy": "2023-05-09T13:29:39.584079Z",
     "iopub.status.idle": "2023-05-09T15:11:34.198596Z",
     "shell.execute_reply": "2023-05-09T15:11:34.197801Z",
     "shell.execute_reply.started": "2023-05-09T13:29:39.584423Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-eca.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=25, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 1 commit. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro P5000, 16279MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 10                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-eca summary: 220 layers, 25284493 parameters, 25284493 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 62 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp16\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 25 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/25      2.3G        2.31        2.46        0.12        0.52: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/25     2.56G         2.3        2.18       0.163       0.649: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/25     2.56G        2.04        2.14        0.28       0.742: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/25     2.56G        1.65        1.45       0.592       0.946: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/25     2.56G        1.44        1.22       0.699       0.968: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/25     2.56G        1.27        1.11       0.739       0.989: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/25     2.56G        1.14       0.959       0.812       0.992: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/25     2.56G        1.02       0.869       0.863       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/25     2.56G       0.935       0.796       0.901       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/25     2.56G       0.847       0.726       0.931       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     11/25     2.56G       0.792       0.692       0.942       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     12/25     2.56G       0.739       0.673       0.955       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     13/25     2.56G       0.704       0.662        0.96       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     14/25     2.56G       0.671       0.647       0.965       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     15/25     2.56G       0.646       0.636       0.966       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     16/25     2.56G       0.621        0.63       0.967       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     17/25     2.56G         0.6       0.623       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     18/25     2.56G       0.588       0.616       0.971       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     19/25     2.56G        0.57        0.61        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     20/25     2.56G       0.559       0.605       0.972       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     21/25     2.56G       0.549       0.602       0.971       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     22/25     2.56G       0.541       0.599       0.972       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     23/25     2.56G       0.533       0.599       0.972       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     24/25     2.56G       0.527         0.6       0.973       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     25/25     2.56G       0.522       0.603        0.97       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (1.683 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp16\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp16/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp16/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1\n",
      "Export:          python export.py --weights runs/train-cls/exp16/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp16/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train.py --model yolov5s-cls.pt --cfg models/yolov5s-eca.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 25 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a86c61b6-357e-4d25-b8a5-74c4d680d7db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-10T10:30:31.301711Z",
     "iopub.status.busy": "2023-05-10T10:30:31.301351Z",
     "iopub.status.idle": "2023-05-10T11:49:59.636352Z",
     "shell.execute_reply": "2023-05-10T11:49:59.635463Z",
     "shell.execute_reply.started": "2023-05-10T10:30:31.301683Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-eca.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=50, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "Command 'git fetch origin' timed out after 5 seconds\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 10                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-eca summary: 220 layers, 25284493 parameters, 25284493 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 62 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp32\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 50 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/50     2.46G        2.29        2.16       0.207       0.718: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/50     2.93G        2.06        1.89        0.32       0.885: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/50     2.93G        1.78        1.56       0.526       0.914: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/50     2.93G        1.47        1.37       0.616       0.937: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/50     2.93G        1.24        1.05       0.768       0.984: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/50     2.93G        1.09       0.896       0.865        0.99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/50     2.93G       0.974       0.867       0.879        0.99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/50     2.93G       0.889        0.78       0.918       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/50     2.93G        0.83       0.721       0.936       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/50     2.93G       0.779       0.701       0.943       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     11/50     2.93G        0.74       0.672       0.959       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     12/50     2.93G       0.712       0.658       0.963       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     13/50     2.93G       0.691       0.657       0.961       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     14/50     2.93G       0.669       0.646       0.967       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     15/50     2.93G       0.653       0.638       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     16/50     2.93G       0.637       0.633        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     17/50     2.93G       0.618       0.624       0.972       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     18/50     2.93G       0.611       0.621       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     19/50     2.93G       0.602       0.618       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     20/50     2.93G       0.591       0.612       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     21/50     2.93G       0.584        0.61       0.976       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     22/50     2.93G       0.572       0.608       0.977       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     23/50     2.93G       0.571       0.607       0.975       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     24/50     2.93G       0.567       0.606       0.975       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     25/50     2.93G       0.552       0.604       0.976       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     26/50     2.93G        0.56       0.603       0.975       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     27/50     2.93G       0.552       0.603       0.974       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     28/50     2.93G       0.541       0.603        0.97       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     29/50     2.93G       0.548       0.605       0.969       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     30/50     2.93G       0.537       0.607       0.967       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     31/50     2.93G       0.542       0.613       0.965       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     32/50     2.93G       0.536        0.62       0.962       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     33/50     2.93G       0.524       0.633       0.961       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     34/50     2.93G       0.541       0.652       0.956       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     35/50     2.93G       0.519       0.675       0.949       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     36/50     2.93G       0.529        0.71       0.936       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     37/50     2.93G       0.523       0.748       0.922       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     38/50     2.93G       0.515       0.797       0.902       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     39/50     2.93G       0.527       0.862       0.878       0.992: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     40/50     2.93G       0.516       0.922        0.85       0.989: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     41/50     2.93G        0.51       0.996       0.812       0.985: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     42/50     2.93G        0.52        1.08       0.775        0.98: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     43/50     2.93G       0.513        1.15       0.746       0.972: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     44/50     2.93G       0.508        1.23       0.714        0.96: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     45/50     2.93G       0.507        1.32       0.673       0.948: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     46/50     2.93G       0.506        1.42       0.622       0.926: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     47/50     2.93G       0.508        1.52       0.583       0.904: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     48/50     2.93G       0.506        1.62       0.542       0.885: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     49/50     2.93G       0.505        1.71       0.512       0.866: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     50/50     2.93G       0.504        1.79       0.467       0.849: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (1.308 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp32\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp32/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp32/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1\n",
      "Export:          python export.py --weights runs/train-cls/exp32/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp32/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train.py --model yolov5s-cls.pt --cfg models/yolov5s-eca.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 50 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b578642d-cbb1-4574-8096-9c4d0d31df93",
   "metadata": {},
   "source": [
    "### 3.2 Validation (E = 10, 25, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39163fc1-7fa1-4964-9e4b-f280f22e1e62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T06:57:10.735203Z",
     "iopub.status.busy": "2023-05-11T06:57:10.733968Z",
     "iopub.status.idle": "2023-05-11T06:57:24.798689Z",
     "shell.execute_reply": "2023-05-11T06:57:24.797868Z",
     "shell.execute_reply.started": "2023-05-11T06:57:10.735168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp14/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-eca summary: 160 layers, 25267789 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:05<00:00,  3.17it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984        0.94       0.999\n",
      "                drinking         182       0.918       0.995\n",
      "         hair and makeup         173       0.775           1\n",
      "     operating the radio         224       0.978           1\n",
      "         reaching behind         189       0.963           1\n",
      "            safe driving         205       0.922           1\n",
      "talking on the phone - left         218       0.991           1\n",
      "talking on the phone - right         209       0.981           1\n",
      "    talking to passenger         182       0.885       0.995\n",
      "          texting - left         209       0.967           1\n",
      "         texting - right         193       0.984           1\n",
      "Accuracy: 0.936200737953186 | Precision: 0.9373711347579956 | Recall: 0.936200737953186\n",
      "F1-Score: 0.9363463521003723 | Mean Average Precision: 0.9781494140625\n",
      "Confusion Matrix:\n",
      "tensor([[167,   7,   1,   1,   0,   1,   0,   0,   0,   5],\n",
      "        [  9, 134,   3,   4,   4,   3,   9,   7,   0,   0],\n",
      "        [  0,   1, 219,   0,   1,   0,   0,   3,   0,   0],\n",
      "        [  0,   3,   0, 182,   0,   0,   0,   4,   0,   0],\n",
      "        [  1,   4,   2,   0, 189,   0,   0,   9,   0,   0],\n",
      "        [  0,   1,   0,   0,   0, 216,   1,   0,   0,   0],\n",
      "        [  0,   0,   1,   0,   0,   0, 205,   2,   0,   1],\n",
      "        [  0,   3,   5,   5,   4,   0,   1, 161,   0,   3],\n",
      "        [  0,   1,   0,   0,   4,   1,   0,   1, 202,   0],\n",
      "        [  0,   0,   0,   0,   1,   0,   0,   2,   0, 190]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1865,   119, 17737,   119,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 1.9ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp68\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp14/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a702e8f9-3f18-417a-8544-49e85bce7eeb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T06:57:24.800664Z",
     "iopub.status.busy": "2023-05-11T06:57:24.800411Z",
     "iopub.status.idle": "2023-05-11T06:57:38.907552Z",
     "shell.execute_reply": "2023-05-11T06:57:38.906588Z",
     "shell.execute_reply.started": "2023-05-11T06:57:24.800639Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp16/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-eca summary: 160 layers, 25267789 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:05<00:00,  3.13it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.973       0.998\n",
      "                drinking         182       0.962           1\n",
      "         hair and makeup         173       0.884       0.988\n",
      "     operating the radio         224       0.978           1\n",
      "         reaching behind         189       0.989           1\n",
      "            safe driving         205        0.99       0.995\n",
      "talking on the phone - left         218       0.995           1\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182        0.94       0.995\n",
      "          texting - left         209       0.981           1\n",
      "         texting - right         193       0.995           1\n",
      "Accuracy: 0.9709140062332153 | Precision: 0.9725649952888489 | Recall: 0.9709140062332153\n",
      "F1-Score: 0.971360445022583 | Mean Average Precision: 0.9932647943496704\n",
      "Confusion Matrix:\n",
      "tensor([[175,   3,   0,   0,   1,   0,   0,   0,   0,   3],\n",
      "        [  9, 153,   0,   0,   4,   4,   2,   1,   0,   0],\n",
      "        [  0,   0, 219,   0,   4,   0,   0,   1,   0,   0],\n",
      "        [  0,   1,   0, 187,   0,   0,   0,   1,   0,   0],\n",
      "        [  1,   1,   0,   0, 203,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0, 217,   0,   1,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0, 208,   0,   0,   1],\n",
      "        [  0,   1,   0,   1,   7,   0,   1, 171,   0,   1],\n",
      "        [  1,   1,   0,   0,   2,   0,   0,   0, 205,   0],\n",
      "        [  0,   0,   0,   0,   1,   0,   0,   0,   0, 192]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1930,    54, 17802,    54,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 1.9ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp69\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp16/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae471a07-f915-4e6e-aaa0-1e002b2b369a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T06:57:38.909151Z",
     "iopub.status.busy": "2023-05-11T06:57:38.908893Z",
     "iopub.status.idle": "2023-05-11T06:57:52.644798Z",
     "shell.execute_reply": "2023-05-11T06:57:52.643695Z",
     "shell.execute_reply.started": "2023-05-11T06:57:38.909125Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp32/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-eca summary: 160 layers, 25267789 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:04<00:00,  3.28it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.977       0.998\n",
      "                drinking         182       0.978           1\n",
      "         hair and makeup         173       0.873       0.988\n",
      "     operating the radio         224       0.991           1\n",
      "         reaching behind         189       0.989           1\n",
      "            safe driving         205        0.98       0.995\n",
      "talking on the phone - left         218           1           1\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182       0.956           1\n",
      "          texting - left         209        0.99       0.995\n",
      "         texting - right         193       0.995           1\n",
      "Accuracy: 0.9748340249061584 | Precision: 0.9765070676803589 | Recall: 0.9748340249061584\n",
      "F1-Score: 0.9753754734992981 | Mean Average Precision: 0.9946268200874329\n",
      "Confusion Matrix:\n",
      "tensor([[178,   3,   1,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  6, 151,   1,   0,   2,   1,   5,   6,   1,   0],\n",
      "        [  0,   0, 222,   0,   1,   0,   0,   1,   0,   0],\n",
      "        [  0,   1,   1, 187,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,   0,   2,   0, 201,   0,   0,   1,   0,   0],\n",
      "        [  0,   0,   0,   0,   0, 218,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0, 208,   0,   0,   1],\n",
      "        [  0,   1,   2,   0,   4,   0,   1, 174,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   1,   0,   1, 207,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   1,   0,   0, 192]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1938,    46, 17810,    46,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 1.9ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp70\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp32/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7c566d-ba1e-44a0-8e4a-d8270526bf8c",
   "metadata": {},
   "source": [
    "## 4.0 3DA using YOLOv5 + SENet + ECANet\n",
    "\n",
    "### Setup:\n",
    "1. Create and Modify models/yolov5s-senet-eca.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3f8cc9-2b0a-46f9-b686-2e1ff7c9b04e",
   "metadata": {},
   "source": [
    "### 4.1 Training (E = 10, 25, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1b7e743-61bb-465b-b723-ac7c384bf132",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T15:17:29.393627Z",
     "iopub.status.busy": "2023-05-09T15:17:29.393283Z",
     "iopub.status.idle": "2023-05-09T15:59:14.629085Z",
     "shell.execute_reply": "2023-05-09T15:59:14.628086Z",
     "shell.execute_reply.started": "2023-05-09T15:17:29.393598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-senet-eca.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=10, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 1 commit. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro P5000, 16279MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1      2048  models.common.SENet                     [1024, 1024]                  \n",
      " 10                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 11                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-senet-eca summary: 227 layers, 25286541 parameters, 25286541 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 64 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp17\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 10 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/10     2.32G        2.23        2.07       0.247       0.777: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/10     2.59G        1.92        1.71       0.451       0.917: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/10     2.59G        1.44        1.33       0.637       0.964: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/10     2.59G         1.2        1.08       0.772       0.975: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/10     2.59G        1.03        0.91       0.861       0.991: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/10     2.59G        0.91       0.809       0.896       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/10     2.59G       0.814       0.745       0.925       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/10     2.59G       0.734       0.685       0.943       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/10     2.59G       0.667       0.659        0.95       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/10     2.59G       0.612       0.628       0.963       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (0.681 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp17\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp17/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp17/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1\n",
      "Export:          python export.py --weights runs/train-cls/exp17/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp17/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train.py --model yolov5s-cls.pt --cfg models/yolov5s-senet-eca.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 10 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d6ae67b-dd3b-48cd-ab23-167ec6b91ccc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-09T16:00:22.138545Z",
     "iopub.status.busy": "2023-05-09T16:00:22.137863Z",
     "iopub.status.idle": "2023-05-09T17:42:42.682130Z",
     "shell.execute_reply": "2023-05-09T17:42:42.681015Z",
     "shell.execute_reply.started": "2023-05-09T16:00:22.138514Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-senet-eca.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=25, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 1 commit. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro P5000, 16279MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1      2048  models.common.SENet                     [1024, 1024]                  \n",
      " 10                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 11                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-senet-eca summary: 227 layers, 25286541 parameters, 25286541 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 64 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp18\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 25 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/25     2.32G        2.23        2.07       0.247       0.777: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/25     2.59G        1.93        1.61       0.494       0.925: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/25     2.59G        1.46        1.36       0.605       0.964: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/25     2.59G        1.23        1.07       0.769       0.989: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/25     2.59G        1.06       0.911       0.853        0.99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/25     2.59G       0.943       0.808       0.897       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/25     2.59G       0.858       0.758       0.923       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/25     2.59G        0.79       0.693       0.946       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/25     2.59G       0.747       0.673       0.945       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/25     2.59G       0.702       0.665       0.953       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     11/25     2.59G       0.676       0.638       0.961       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     12/25     2.59G       0.649       0.624       0.967       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     13/25     2.59G       0.628       0.627       0.971       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     14/25     2.59G       0.606       0.615       0.973           1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     15/25     2.59G       0.591       0.605       0.973       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     16/25     2.59G       0.581       0.598       0.975           1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     17/25     2.59G       0.564        0.59       0.978           1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     18/25     2.59G       0.558       0.585       0.977           1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     19/25     2.59G       0.543       0.579       0.977           1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     20/25     2.59G       0.543       0.578       0.979           1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     21/25     2.59G       0.533       0.574       0.979           1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     22/25     2.59G       0.526       0.572        0.98           1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     23/25     2.59G       0.521        0.57        0.98       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     24/25     2.59G       0.516        0.57        0.98       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     25/25     2.59G       0.514        0.57       0.979       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (1.690 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp18\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp18/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp18/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1\n",
      "Export:          python export.py --weights runs/train-cls/exp18/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp18/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train.py --model yolov5s-cls.pt --cfg models/yolov5s-senet-eca.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 25 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01e0a452-d5f1-42a5-9c33-4f75a4ba1dda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-10T11:49:59.637704Z",
     "iopub.status.busy": "2023-05-10T11:49:59.637428Z",
     "iopub.status.idle": "2023-05-10T13:09:29.924520Z",
     "shell.execute_reply": "2023-05-10T13:09:29.923574Z",
     "shell.execute_reply.started": "2023-05-10T11:49:59.637677Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-senet-eca.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=50, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 1 commit. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1      2048  models.common.SENet                     [1024, 1024]                  \n",
      " 10                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 11                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-senet-eca summary: 227 layers, 25286541 parameters, 25286541 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 64 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp33\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 50 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/50     2.47G        2.22        2.28       0.166       0.666: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/50     2.94G         1.9        1.62       0.488       0.923: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/50     2.94G        1.47        1.37       0.625       0.954: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/50     2.94G        1.24        1.14       0.742        0.98: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/50     2.94G        1.09       0.952       0.826        0.99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/50     2.94G       0.976       0.862        0.87       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/50     2.94G       0.895         0.8       0.901       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/50     2.94G       0.822       0.734       0.928       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/50     2.94G       0.774       0.703        0.94       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/50     2.94G        0.73       0.673       0.953       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     11/50     2.94G         0.7       0.655       0.956       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     12/50     2.94G        0.67       0.645       0.962           1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     13/50     2.94G       0.657       0.641       0.964       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     14/50     2.94G       0.632        0.63       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     15/50     2.94G       0.622       0.627       0.967       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     16/50     2.94G       0.612       0.622       0.967       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     17/50     2.94G       0.591       0.616       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     18/50     2.94G       0.591       0.617       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     19/50     2.94G       0.579       0.616       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     20/50     2.94G       0.575       0.613        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     21/50     2.94G       0.565       0.608       0.972       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     22/50     2.94G       0.564       0.607       0.972       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     23/50     2.94G       0.554       0.605       0.972       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     24/50     2.94G       0.555       0.604       0.973       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     25/50     2.94G       0.546       0.603       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     26/50     2.94G        0.55       0.603       0.972       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     27/50     2.94G       0.538       0.602       0.972       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     28/50     2.94G       0.541       0.602       0.973       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     29/50     2.94G       0.539       0.603       0.972       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     30/50     2.94G       0.537       0.605        0.97       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     31/50     2.94G       0.524       0.609       0.968       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     32/50     2.94G       0.533       0.615       0.965       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     33/50     2.94G       0.527       0.623       0.963       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     34/50     2.94G       0.527       0.637       0.955       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     35/50     2.94G        0.52       0.654       0.946       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     36/50     2.94G       0.521       0.682       0.933       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     37/50     2.94G       0.523       0.713       0.923       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     38/50     2.94G       0.513       0.755       0.904       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     39/50     2.94G       0.523       0.811       0.884       0.993: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     40/50     2.94G       0.515       0.864       0.869       0.991: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     41/50     2.94G       0.511       0.928       0.838       0.989: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     42/50     2.94G       0.512           1       0.793       0.987: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     43/50     2.94G       0.512        1.08       0.758       0.986: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     44/50     2.94G       0.509        1.16       0.708       0.983: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     45/50     2.94G       0.508        1.25       0.661       0.977: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     46/50     2.94G       0.507        1.36       0.611       0.967: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     47/50     2.94G       0.507        1.47       0.553        0.96: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     48/50     2.94G       0.506        1.58       0.497       0.951: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     49/50     2.94G       0.505        1.69       0.444       0.933: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     50/50     2.94G       0.505         1.8       0.392       0.919: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (1.310 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp33\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp33/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp33/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1\n",
      "Export:          python export.py --weights runs/train-cls/exp33/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp33/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train.py --model yolov5s-cls.pt --cfg models/yolov5s-senet-eca.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 50 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b80bf2-8ce7-49be-aad3-90ba8bb2cd76",
   "metadata": {},
   "source": [
    "### 4.2 Validation (E = 10, 25, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37f111ba-1e23-4a98-81b5-36fbe3ff5815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T07:01:24.038807Z",
     "iopub.status.busy": "2023-05-11T07:01:24.038450Z",
     "iopub.status.idle": "2023-05-11T07:01:38.184205Z",
     "shell.execute_reply": "2023-05-11T07:01:38.183290Z",
     "shell.execute_reply.started": "2023-05-11T07:01:24.038776Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp17/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-senet-eca summary: 167 layers, 25269837 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:05<00:00,  3.09it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.963       0.999\n",
      "                drinking         182       0.962           1\n",
      "         hair and makeup         173       0.861           1\n",
      "     operating the radio         224       0.991       0.996\n",
      "         reaching behind         189       0.942           1\n",
      "            safe driving         205       0.961           1\n",
      "talking on the phone - left         218           1           1\n",
      "talking on the phone - right         209       0.986           1\n",
      "    talking to passenger         182       0.923           1\n",
      "          texting - left         209        0.99           1\n",
      "         texting - right         193        0.99           1\n",
      "Accuracy: 0.9605447053909302 | Precision: 0.9619057178497314 | Recall: 0.9605447053909302\n",
      "F1-Score: 0.9610152244567871 | Mean Average Precision: 0.9901090860366821\n",
      "Confusion Matrix:\n",
      "tensor([[175,   3,   0,   0,   1,   0,   0,   0,   0,   3],\n",
      "        [  6, 149,   1,   3,   1,   3,   5,   5,   0,   0],\n",
      "        [  0,   0, 222,   0,   1,   0,   0,   1,   0,   0],\n",
      "        [  0,   4,   5, 178,   0,   0,   0,   2,   0,   0],\n",
      "        [  1,   2,   2,   0, 197,   0,   0,   3,   0,   0],\n",
      "        [  0,   0,   0,   0,   0, 218,   0,   0,   0,   0],\n",
      "        [  1,   0,   0,   2,   0,   0, 206,   0,   0,   0],\n",
      "        [  1,   2,   1,   2,   4,   0,   1, 168,   0,   3],\n",
      "        [  0,   0,   0,   0,   1,   1,   0,   0, 207,   0],\n",
      "        [  0,   0,   0,   0,   1,   0,   1,   0,   0, 191]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1911,    73, 17783,    73,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 1.9ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp71\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp17/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36cb424f-a2ea-4465-9785-c3066d7bcbd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T07:01:38.185968Z",
     "iopub.status.busy": "2023-05-11T07:01:38.185719Z",
     "iopub.status.idle": "2023-05-11T07:01:51.991440Z",
     "shell.execute_reply": "2023-05-11T07:01:51.990426Z",
     "shell.execute_reply.started": "2023-05-11T07:01:38.185942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp18/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-senet-eca summary: 167 layers, 25269837 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:04<00:00,  3.28it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984        0.98       0.999\n",
      "                drinking         182       0.967           1\n",
      "         hair and makeup         173        0.89       0.994\n",
      "     operating the radio         224       0.982           1\n",
      "         reaching behind         189           1           1\n",
      "            safe driving         205        0.99           1\n",
      "talking on the phone - left         218           1           1\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182       0.978           1\n",
      "          texting - left         209       0.995           1\n",
      "         texting - right         193        0.99           1\n",
      "Accuracy: 0.9787683486938477 | Precision: 0.9794500470161438 | Recall: 0.9787683486938477\n",
      "F1-Score: 0.9789444804191589 | Mean Average Precision: 0.9969938397407532\n",
      "Confusion Matrix:\n",
      "tensor([[176,   5,   0,   0,   0,   0,   0,   0,   0,   1],\n",
      "        [  5, 154,   0,   1,   2,   3,   3,   5,   0,   0],\n",
      "        [  0,   1, 220,   0,   2,   0,   0,   1,   0,   0],\n",
      "        [  0,   0,   0, 189,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,   0,   0,   0, 203,   0,   0,   1,   0,   0],\n",
      "        [  0,   0,   0,   0,   0, 218,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0, 208,   0,   0,   1],\n",
      "        [  0,   1,   0,   1,   1,   0,   1, 178,   0,   0],\n",
      "        [  0,   0,   0,   0,   1,   0,   0,   0, 208,   0],\n",
      "        [  0,   0,   0,   0,   1,   0,   1,   0,   0, 191]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1945,    39, 17817,    39,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 1.9ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp72\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp18/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55e218c2-26f0-4710-9613-ec5d9f24c8fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-11T07:01:51.994716Z",
     "iopub.status.busy": "2023-05-11T07:01:51.994363Z",
     "iopub.status.idle": "2023-05-11T07:02:05.870282Z",
     "shell.execute_reply": "2023-05-11T07:02:05.869130Z",
     "shell.execute_reply.started": "2023-05-11T07:01:51.994682Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp33/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-senet-eca summary: 167 layers, 25269837 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:04<00:00,  3.30it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.974       0.998\n",
      "                drinking         182       0.967           1\n",
      "         hair and makeup         173       0.879       0.994\n",
      "     operating the radio         224       0.982           1\n",
      "         reaching behind         189       0.979           1\n",
      "            safe driving         205       0.976           1\n",
      "talking on the phone - left         218           1           1\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182       0.956       0.989\n",
      "          texting - left         209       0.995           1\n",
      "         texting - right         193        0.99           1\n",
      "Accuracy: 0.9718345999717712 | Precision: 0.9738524556159973 | Recall: 0.9718345999717712\n",
      "F1-Score: 0.9725775718688965 | Mean Average Precision: 0.9953891634941101\n",
      "Confusion Matrix:\n",
      "tensor([[176,   3,   0,   0,   1,   0,   0,   0,   0,   2],\n",
      "        [  6, 152,   3,   1,   3,   3,   5,   0,   0,   0],\n",
      "        [  0,   0, 220,   0,   2,   0,   0,   2,   0,   0],\n",
      "        [  0,   1,   3, 185,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,   2,   1,   0, 200,   0,   0,   0,   0,   1],\n",
      "        [  0,   0,   0,   0,   0, 218,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0, 208,   0,   0,   1],\n",
      "        [  0,   1,   1,   0,   5,   0,   1, 174,   0,   0],\n",
      "        [  0,   0,   1,   0,   0,   0,   0,   0, 208,   0],\n",
      "        [  0,   0,   0,   0,   2,   0,   0,   0,   0, 191]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1932,    52, 17804,    52,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 2.1ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp73\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp33/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5388b0e8-2137-4672-9147-a012b9ee998a",
   "metadata": {},
   "source": [
    "## 5.0 3DA w/ YOLOv5 w/o Augmentations (Benchmark)\n",
    "\n",
    "### Setup: \n",
    "\n",
    "1. Download dataset w/o augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a68befa-b366-4087-ba19-68f848dbc589",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T16:44:53.302187Z",
     "iopub.status.busy": "2023-05-15T16:44:53.301837Z",
     "iopub.status.idle": "2023-05-15T16:45:28.332816Z",
     "shell.execute_reply": "2023-05-15T16:45:28.331950Z",
     "shell.execute_reply.started": "2023-05-15T16:44:53.302158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks\n",
      "/notebooks/datasets_noaug\n",
      "Requirement already satisfied: roboflow in /usr/local/lib/python3.9/dist-packages (1.0.8)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.9/dist-packages (from roboflow) (9.2.0)\n",
      "Requirement already satisfied: cycler==0.10.0 in /usr/local/lib/python3.9/dist-packages (from roboflow) (0.10.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.9/dist-packages (from roboflow) (1.26.14)\n",
      "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.9/dist-packages (from roboflow) (2.10)\n",
      "Requirement already satisfied: certifi==2022.12.7 in /usr/local/lib/python3.9/dist-packages (from roboflow) (2022.12.7)\n",
      "Requirement already satisfied: opencv-python>=4.1.2 in /usr/local/lib/python3.9/dist-packages (from roboflow) (4.6.0.66)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.9/dist-packages (from roboflow) (1.4.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from roboflow) (2.28.2)\n",
      "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.9/dist-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from roboflow) (1.14.0)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.9/dist-packages (from roboflow) (5.4.1)\n",
      "Requirement already satisfied: wget in /usr/local/lib/python3.9/dist-packages (from roboflow) (3.2)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.9/dist-packages (from roboflow) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/dist-packages (from roboflow) (2.8.2)\n",
      "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.9/dist-packages (from roboflow) (4.0.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.9/dist-packages (from roboflow) (1.23.4)\n",
      "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.9/dist-packages (from roboflow) (0.10.1)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.9/dist-packages (from roboflow) (4.64.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from roboflow) (3.6.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->roboflow) (4.38.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->roboflow) (1.0.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->roboflow) (23.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->roboflow) (2.1.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n",
      "Downloading Dataset Version Zip in Driver-Distraction-Detection-5 to folder: 100% [122979070 / 122979070] bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Dataset Version Zip to Driver-Distraction-Detection-5 in folder:: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9944/9944 [00:10<00:00, 922.55it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/datasets_noaug/Driver-Distraction-Detection-5\n",
      "/notebooks/yolov5\n"
     ]
    }
   ],
   "source": [
    "%cd /notebooks\n",
    "%rm -r /notebooks/datasets_noaug\n",
    "%mkdir /notebooks/datasets_noaug\n",
    "%cd /notebooks/datasets_noaug\n",
    "\n",
    "!pip install roboflow\n",
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"8CMZTXltcjnnKhuvAKuJ\")\n",
    "project = rf.workspace(\"fyp-cli-v01\").project(\"driver-distraction-detection\")\n",
    "dataset = project.version(5).download(\"folder\")\n",
    "\n",
    "\n",
    "%cd /notebooks/datasets_noaug/Driver-Distraction-Detection-5\n",
    "%mv valid val\n",
    "\n",
    "%cd /notebooks/yolov5/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d109a9a3-d0cf-4ddc-9418-2d76c7d035c3",
   "metadata": {},
   "source": [
    "## 5.1 Training (E = 10, 25, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad1dcb96-ddf6-4b5c-a539-7e48e7a58ff6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T16:47:00.234189Z",
     "iopub.status.busy": "2023-05-15T16:47:00.233817Z",
     "iopub.status.idle": "2023-05-15T16:53:16.549661Z",
     "shell.execute_reply": "2023-05-15T16:53:16.548573Z",
     "shell.execute_reply.started": "2023-05-15T16:47:00.234156Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-cls.yaml, data=/notebooks/datasets_noaug/Driver-Distraction-Detection-5/, epochs=10, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 5 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-cls summary: 216 layers, 25284490 parameters, 25284490 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 61 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp37\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets_noaug/Driver-Distraction-Detection-5 dataset with 10 classes for 10 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/10     2.42G        2.31         2.3       0.113       0.523: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/10      2.9G        2.27        4.89       0.114       0.483: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/10      2.9G        1.71        1.64       0.489       0.935: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/10      2.9G        1.33        1.27        0.66       0.973: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/10      2.9G        1.13        1.04       0.783       0.982: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/10      2.9G        0.97        1.04       0.822        0.99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/10      2.9G       0.868        1.04       0.784        0.99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/10      2.9G        0.77       0.816       0.891       0.989: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/10      2.9G       0.696        0.71       0.932       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/10      2.9G       0.643       0.676       0.951       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (0.090 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp37\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp37/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp37/weights/best.pt --data /notebooks/datasets_noaug/Driver-Distraction-Detection-5\n",
      "Export:          python export.py --weights runs/train-cls/exp37/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp37/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train.py --model yolov5s-cls.pt --cfg models/yolov5s-cls.yaml --data /notebooks/datasets_noaug/Driver-Distraction-Detection-5/ --epochs 10 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "97e7f895-b0f5-47f1-b24c-ece33ad2f142",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T16:53:16.551656Z",
     "iopub.status.busy": "2023-05-15T16:53:16.551395Z",
     "iopub.status.idle": "2023-05-15T17:07:44.057102Z",
     "shell.execute_reply": "2023-05-15T17:07:44.056290Z",
     "shell.execute_reply.started": "2023-05-15T16:53:16.551628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-cls.yaml, data=/notebooks/datasets_noaug/Driver-Distraction-Detection-5/, epochs=25, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 5 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-cls summary: 216 layers, 25284490 parameters, 25284490 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 61 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp38\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets_noaug/Driver-Distraction-Detection-5 dataset with 10 classes for 25 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/25     2.42G        2.31         2.3       0.113       0.523: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/25      2.9G        2.09        1.99       0.321       0.835: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/25      2.9G        1.58        1.37       0.636       0.967: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/25      2.9G        1.28        1.28       0.659       0.969: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/25      2.9G        1.09        1.11       0.759       0.982: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/25      2.9G       0.951        1.06       0.792       0.982: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/25      2.9G       0.879       0.897       0.854       0.993: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/25      2.9G        0.81       0.852       0.879        0.99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/25      2.9G        0.75       0.772       0.916       0.993: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/25      2.9G       0.717       0.796       0.918       0.992: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     11/25      2.9G       0.674       0.712       0.933       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     12/25      2.9G        0.66       0.721       0.934       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     13/25      2.9G        0.63       0.698       0.946       0.993: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     14/25      2.9G       0.622       0.674       0.956       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     15/25      2.9G       0.595       0.632       0.965       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     16/25      2.9G       0.583       0.638       0.963       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     17/25      2.9G       0.572        0.62        0.97       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     18/25      2.9G       0.557       0.612        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     19/25      2.9G       0.547       0.596       0.972       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     20/25      2.9G       0.541       0.585       0.976       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     21/25      2.9G       0.533       0.586       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     22/25      2.9G       0.529       0.583       0.974       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     23/25      2.9G       0.524       0.574       0.977       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     24/25      2.9G       0.521       0.573       0.976       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     25/25      2.9G       0.518       0.571       0.976       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (0.226 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp38\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp38/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp38/weights/best.pt --data /notebooks/datasets_noaug/Driver-Distraction-Detection-5\n",
      "Export:          python export.py --weights runs/train-cls/exp38/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp38/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train.py --model yolov5s-cls.pt --cfg models/yolov5s-cls.yaml --data /notebooks/datasets_noaug/Driver-Distraction-Detection-5/ --epochs 25 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "099ec4a0-8092-421d-a210-426d8763ffa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T17:11:53.174757Z",
     "iopub.status.busy": "2023-05-15T17:11:53.173769Z",
     "iopub.status.idle": "2023-05-15T17:40:19.710475Z",
     "shell.execute_reply": "2023-05-15T17:40:19.708965Z",
     "shell.execute_reply.started": "2023-05-15T17:11:53.174723Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-cls.yaml, data=/notebooks/datasets_noaug/Driver-Distraction-Detection-5/, epochs=50, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 5 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-cls summary: 216 layers, 25284490 parameters, 25284490 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 61 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp40\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets_noaug/Driver-Distraction-Detection-5 dataset with 10 classes for 50 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/50     2.42G        2.31         2.3       0.113       0.523: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/50      2.9G        2.12        2.13        0.29       0.689: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/50      2.9G        1.68        1.72       0.438       0.918: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/50      2.9G         1.4        1.31       0.678       0.971: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/50      2.9G        1.14        1.15        0.74       0.984: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/50      2.9G       0.999        1.04       0.791       0.988: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/50      2.9G       0.917       0.876       0.877       0.992: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/50      2.9G       0.855        0.84       0.882       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/50      2.9G       0.803       0.991       0.791       0.992: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/50      2.9G       0.772       0.966       0.829       0.988: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     11/50      2.9G       0.741       0.751       0.927       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     12/50      2.9G       0.711       0.805       0.905       0.993: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     13/50      2.9G       0.697       0.749        0.92       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     14/50      2.9G       0.675        0.74       0.925       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     15/50      2.9G       0.674       0.687       0.945       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     16/50      2.9G       0.646       0.666       0.958       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     17/50      2.9G        0.65       0.675       0.952       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     18/50      2.9G       0.631       0.651       0.956       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     19/50      2.9G       0.613       0.653       0.957       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     20/50      2.9G       0.614       0.656       0.955       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     21/50      2.9G       0.604       0.637       0.965       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     22/50      2.9G       0.601       0.637       0.964       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     23/50      2.9G       0.585        0.61        0.97       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     24/50      2.9G         0.6       0.603       0.973       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     25/50      2.9G       0.565       0.597       0.971       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     26/50      2.9G       0.568       0.608       0.969       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     27/50      2.9G       0.575       0.613       0.964       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     28/50      2.9G       0.567       0.587       0.978       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     29/50      2.9G       0.547       0.587       0.973       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     30/50      2.9G       0.558       0.589       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     31/50      2.9G       0.558       0.579       0.978       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     32/50      2.9G       0.538       0.577       0.976       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     33/50      2.9G       0.537       0.575       0.976       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     34/50      2.9G       0.535       0.576       0.977       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     35/50      2.9G       0.566       0.593       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     36/50      2.9G       0.535       0.569       0.978       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     37/50      2.9G       0.523       0.567       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     38/50      2.9G        0.52       0.563       0.978       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     39/50      2.9G       0.519       0.562       0.977       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     40/50      2.9G       0.532       0.573       0.978       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     41/50      2.9G        0.54        0.57       0.978       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     42/50      2.9G       0.517       0.562       0.978       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     43/50      2.9G       0.514       0.561       0.978       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     44/50      2.9G       0.512       0.559       0.977       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     45/50      2.9G       0.511       0.558       0.978       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     46/50      2.9G       0.511       0.557       0.978       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     47/50      2.9G        0.51       0.557       0.978       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     48/50      2.9G        0.51       0.557       0.977       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     49/50      2.9G       0.508       0.556       0.978       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     50/50      2.9G       0.507       0.556       0.979       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (0.459 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp40\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp40/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp40/weights/best.pt --data /notebooks/datasets_noaug/Driver-Distraction-Detection-5\n",
      "Export:          python export.py --weights runs/train-cls/exp40/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp40/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train.py --model yolov5s-cls.pt --cfg models/yolov5s-cls.yaml --data /notebooks/datasets_noaug/Driver-Distraction-Detection-5/ --epochs 50 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da5e7a6-62bf-42f8-8811-8bfb486d0c23",
   "metadata": {},
   "source": [
    "## 5.2 Validation (E = 10, 25, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "147b0822-9053-411f-b3ee-d4e5de2bbf55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T17:40:19.713255Z",
     "iopub.status.busy": "2023-05-15T17:40:19.712841Z",
     "iopub.status.idle": "2023-05-15T17:40:33.535300Z",
     "shell.execute_reply": "2023-05-15T17:40:33.534158Z",
     "shell.execute_reply.started": "2023-05-15T17:40:19.713220Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets_noaug/Driver-Distraction-Detection-5, weights=['runs/train-cls/exp37/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-cls summary: 156 layers, 25267786 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:04<00:00,  3.23it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.951       0.994\n",
      "                drinking         182       0.929       0.984\n",
      "         hair and makeup         173       0.838       0.983\n",
      "     operating the radio         224       0.978           1\n",
      "         reaching behind         189       0.952           1\n",
      "            safe driving         205       0.995       0.995\n",
      "talking on the phone - left         218           1           1\n",
      "talking on the phone - right         209       0.957           1\n",
      "    talking to passenger         182       0.852       0.984\n",
      "          texting - left         209       0.986       0.995\n",
      "         texting - right         193        0.99           1\n",
      "Accuracy: 0.947577178478241 | Precision: 0.9505592584609985 | Recall: 0.947577178478241\n",
      "F1-Score: 0.9482375979423523 | Mean Average Precision: 0.9777251482009888\n",
      "Confusion Matrix:\n",
      "tensor([[169,   6,   2,   0,   2,   0,   0,   1,   0,   2],\n",
      "        [  6, 145,   2,   6,   6,   1,   1,   3,   2,   1],\n",
      "        [  0,   2, 219,   0,   2,   0,   0,   1,   0,   0],\n",
      "        [  0,   3,   3, 180,   0,   0,   0,   1,   2,   0],\n",
      "        [  0,   1,   0,   0, 204,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0, 218,   0,   0,   0,   0],\n",
      "        [  1,   5,   0,   1,   1,   0, 200,   0,   0,   1],\n",
      "        [  1,   4,   0,   3,  16,   0,   1, 155,   0,   2],\n",
      "        [  0,   0,   1,   0,   1,   0,   0,   0, 206,   1],\n",
      "        [  0,   0,   1,   0,   1,   0,   0,   0,   0, 191]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1887,    97, 17759,    97,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 2.1ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp74\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp37/weights/best.pt --data /notebooks/datasets_noaug/Driver-Distraction-Detection-5 --img 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57ff4b4a-f0e5-4a08-b703-c839fb3ee1b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T17:40:33.537099Z",
     "iopub.status.busy": "2023-05-15T17:40:33.536796Z",
     "iopub.status.idle": "2023-05-15T17:40:47.341379Z",
     "shell.execute_reply": "2023-05-15T17:40:47.340451Z",
     "shell.execute_reply.started": "2023-05-15T17:40:33.537072Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets_noaug/Driver-Distraction-Detection-5, weights=['runs/train-cls/exp38/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-cls summary: 156 layers, 25267786 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:05<00:00,  3.15it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.977       0.997\n",
      "                drinking         182       0.956       0.995\n",
      "         hair and makeup         173       0.908       0.988\n",
      "     operating the radio         224       0.987           1\n",
      "         reaching behind         189       0.989           1\n",
      "            safe driving         205       0.985       0.995\n",
      "talking on the phone - left         218           1           1\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182       0.951       0.995\n",
      "          texting - left         209        0.99           1\n",
      "         texting - right         193       0.995           1\n",
      "Accuracy: 0.9755963683128357 | Precision: 0.9764944314956665 | Recall: 0.9755963683128357\n",
      "F1-Score: 0.9759312272071838 | Mean Average Precision: 0.9938055276870728\n",
      "Confusion Matrix:\n",
      "tensor([[174,   4,   1,   0,   0,   0,   1,   0,   0,   2],\n",
      "        [  5, 157,   2,   3,   1,   0,   2,   2,   0,   1],\n",
      "        [  0,   0, 221,   0,   3,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0, 187,   0,   0,   0,   2,   0,   0],\n",
      "        [  1,   1,   0,   0, 202,   1,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0, 218,   0,   0,   0,   0],\n",
      "        [  0,   1,   0,   0,   0,   0, 208,   0,   0,   0],\n",
      "        [  1,   2,   0,   2,   4,   0,   0, 173,   0,   0],\n",
      "        [  0,   0,   0,   0,   1,   1,   0,   0, 207,   0],\n",
      "        [  0,   0,   0,   0,   1,   0,   0,   0,   0, 192]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1939,    45, 17811,    45,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 1.9ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp75\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp38/weights/best.pt --data /notebooks/datasets_noaug/Driver-Distraction-Detection-5 --img 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9b0b732a-c583-40df-a180-8ebb4df70616",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-15T17:40:47.347033Z",
     "iopub.status.busy": "2023-05-15T17:40:47.346345Z",
     "iopub.status.idle": "2023-05-15T17:41:01.128748Z",
     "shell.execute_reply": "2023-05-15T17:41:01.127952Z",
     "shell.execute_reply.started": "2023-05-15T17:40:47.347001Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets_noaug/Driver-Distraction-Detection-5, weights=['runs/train-cls/exp40/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 4000, 7982MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-cls summary: 156 layers, 25267786 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:05<00:00,  3.13it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.979       0.999\n",
      "                drinking         182       0.962       0.995\n",
      "         hair and makeup         173       0.908           1\n",
      "     operating the radio         224       0.982           1\n",
      "         reaching behind         189       0.989           1\n",
      "            safe driving         205        0.99           1\n",
      "talking on the phone - left         218           1           1\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182       0.962           1\n",
      "          texting - left         209        0.99           1\n",
      "         texting - right         193       0.995           1\n",
      "Accuracy: 0.9772860407829285 | Precision: 0.9780105352401733 | Recall: 0.9772860407829285\n",
      "F1-Score: 0.9775153994560242 | Mean Average Precision: 0.9965338110923767\n",
      "Confusion Matrix:\n",
      "tensor([[175,   3,   1,   0,   1,   0,   0,   1,   0,   1],\n",
      "        [  3, 157,   1,   5,   2,   1,   0,   4,   0,   0],\n",
      "        [  0,   0, 220,   0,   2,   0,   0,   2,   0,   0],\n",
      "        [  0,   1,   0, 187,   0,   0,   0,   1,   0,   0],\n",
      "        [  0,   1,   0,   0, 203,   0,   0,   1,   0,   0],\n",
      "        [  0,   0,   0,   0,   0, 218,   0,   0,   0,   0],\n",
      "        [  1,   0,   0,   0,   0,   0, 208,   0,   0,   0],\n",
      "        [  1,   1,   1,   1,   2,   0,   0, 175,   0,   1],\n",
      "        [  0,   0,   0,   0,   1,   1,   0,   0, 207,   0],\n",
      "        [  0,   0,   0,   0,   1,   0,   0,   0,   0, 192]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1942,    42, 17814,    42,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 1.8ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp76\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp40/weights/best.pt --data /notebooks/datasets_noaug/Driver-Distraction-Detection-5 --img 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c8ac5e9-a2c1-4ad0-81fa-f0a846fbfcb8",
   "metadata": {},
   "source": [
    "## Phase 2: Early Stopping and Learning Rate Scheduler\n",
    "\n",
    "Test best model with learning rate scheduler: \"step\", \"cosine\", and \"polynomial\"\n",
    "\n",
    "Then, test same model with and without early stopping\n",
    "\n",
    "Best model: YOLOv5 + Both\n",
    "\n",
    "## Without Early Stopping\n",
    "### Cosine LRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8af3dea4-0eca-4c59-b7ff-b828cac236e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T06:41:00.828381Z",
     "iopub.status.busy": "2023-05-23T06:41:00.828142Z",
     "iopub.status.idle": "2023-05-23T07:13:29.910999Z",
     "shell.execute_reply": "2023-05-23T07:13:29.910369Z",
     "shell.execute_reply.started": "2023-05-23T06:41:00.828361Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train_noes_cos-lrs: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-senet-eca.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=25, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "remote: Enumerating objects: 29, done.\u001b[K\n",
      "remote: Counting objects: 100% (29/29), done.\u001b[K\n",
      "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
      "remote: Total 29 (delta 7), reused 17 (delta 5), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (29/29), 53.73 KiB | 821.00 KiB/s, done.\n",
      "From https://github.com/ultralytics/yolov5\n",
      "   5deff14..6e04b94  master     -> origin/master\n",
      "   73b87dc..4f0920d  snyk-fix-6c9eeb3b0a7596bd3087093a737a3c49 -> origin/snyk-fix-6c9eeb3b0a7596bd3087093a737a3c49\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 9 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (NVIDIA RTX A4000, 16117MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1      2048  models.common.SENet                     [1024, 1024]                  \n",
      " 10                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 11                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-senet-eca summary: 227 layers, 25286541 parameters, 25286541 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 64 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp41\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 25 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/25      2.3G        2.31        2.35       0.104       0.508: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/25      2.8G         2.3        2.31      0.0968        0.51: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/25      2.8G        2.26        2.22       0.165       0.644: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/25      2.8G        2.11        2.01       0.273       0.769: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/25      2.8G        1.98        1.87       0.342       0.858: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/25      2.8G        1.79        1.62       0.492       0.911: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/25      2.8G        1.53        1.27       0.652       0.972: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/25      2.8G        1.34        1.09       0.746       0.986: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/25      2.8G        1.19       0.974       0.824       0.991: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/25      2.8G        1.06       0.873       0.869       0.993: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     11/25      2.8G       0.953       0.782       0.912       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     12/25      2.8G       0.867       0.742       0.927       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     13/25      2.8G       0.803       0.709        0.94       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     14/25      2.8G       0.749       0.682       0.953       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     15/25      2.8G       0.705       0.663       0.955       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     16/25      2.8G       0.665       0.651       0.958       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     17/25      2.8G       0.632        0.64       0.961       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     18/25      2.8G       0.607       0.633       0.962       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     19/25      2.8G       0.583       0.625       0.964       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     20/25      2.8G       0.565       0.619       0.966       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     21/25      2.8G       0.554       0.615       0.968       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     22/25      2.8G       0.544       0.612       0.968       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     23/25      2.8G       0.538        0.61       0.969       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     24/25      2.8G       0.534       0.608       0.969       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     25/25      2.8G       0.532       0.607        0.97       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (0.526 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp41\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp41/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp41/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1\n",
      "Export:          python export.py --weights runs/train-cls/exp41/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp41/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train_noes_cos-lrs.py --model yolov5s-cls.pt --cfg models/yolov5s-senet-eca.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 25 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f995471e-cbeb-4d62-a9cd-2d03ea7fc994",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T02:13:59.221693Z",
     "iopub.status.busy": "2023-05-26T02:13:59.221351Z",
     "iopub.status.idle": "2023-05-26T03:30:47.275972Z",
     "shell.execute_reply": "2023-05-26T03:30:47.275185Z",
     "shell.execute_reply.started": "2023-05-26T02:13:59.221631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train_noes_cos-lrs: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-senet-eca.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=50, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 10 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 5000, 16125MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1      2048  models.common.SENet                     [1024, 1024]                  \n",
      " 10                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 11                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-senet-eca summary: 227 layers, 25286541 parameters, 25286541 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 64 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp61\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 50 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/50     2.47G        2.27        2.09       0.206       0.757: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/50     2.94G        1.96        1.56       0.521        0.94: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/50     2.94G        1.48        1.29       0.679       0.965: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/50     2.94G        1.27        1.16       0.713        0.98: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/50     2.94G        1.15        1.05       0.775       0.986: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/50     2.94G        1.06       0.892       0.853       0.991: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/50     2.94G        0.98       0.855       0.864       0.993: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/50     2.94G        0.91       0.816       0.881       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/50     2.94G       0.857       0.748       0.911       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/50     2.94G       0.803       0.715       0.934       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     11/50     2.94G       0.766       0.686       0.947       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     12/50     2.94G       0.726       0.685       0.944       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     13/50     2.94G       0.698       0.667       0.952       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     14/50     2.94G       0.674       0.655       0.958       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     15/50     2.94G       0.653       0.641       0.964       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     16/50     2.94G       0.633       0.636       0.966       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     17/50     2.94G       0.618       0.634       0.968       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     18/50     2.94G       0.606       0.629       0.969       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     19/50     2.94G       0.594       0.626       0.969       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     20/50     2.94G       0.585       0.624        0.97       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     21/50     2.94G       0.579       0.623       0.969       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     22/50     2.94G       0.572       0.621       0.972       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     23/50     2.94G       0.559       0.618       0.972       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     24/50     2.94G       0.558       0.617       0.971       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     25/50     2.94G       0.553       0.617       0.971       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     26/50     2.94G       0.545       0.617       0.968       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     27/50     2.94G       0.542       0.618       0.967       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     28/50     2.94G       0.537       0.618       0.965       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     29/50     2.94G       0.535       0.619       0.963       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     30/50     2.94G       0.529       0.622       0.961       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     31/50     2.94G        0.53       0.627       0.957       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     32/50     2.94G       0.527       0.636       0.954       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     33/50     2.94G        0.52       0.652       0.946       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     34/50     2.94G        0.52       0.679       0.938       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     35/50     2.94G       0.519       0.719       0.925       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     36/50     2.94G       0.517       0.774       0.907       0.991: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     37/50     2.94G       0.512        0.85       0.874       0.991: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     38/50     2.94G       0.512       0.954       0.832       0.987: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     39/50     2.94G       0.512        1.08       0.766       0.982: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     40/50     2.94G        0.51        1.22       0.686       0.975: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     41/50     2.94G       0.508        1.37       0.607       0.966: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     42/50     2.94G       0.508        1.52       0.528       0.951: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     43/50     2.94G       0.507        1.67       0.451       0.936: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     44/50     2.94G       0.506        1.81        0.38        0.91: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     45/50     2.94G       0.506        1.94       0.332       0.888: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     46/50     2.94G       0.505        2.05       0.282       0.864: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     47/50     2.94G       0.505        2.14       0.244       0.845: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     48/50     2.94G       0.505        2.21       0.215       0.828: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     49/50     2.94G       0.505        2.26       0.193        0.81: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     50/50     2.94G       0.505         2.3       0.179       0.802: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (1.265 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp61\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp61/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp61/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1\n",
      "Export:          python export.py --weights runs/train-cls/exp61/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp61/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train_noes_cos-lrs.py --model yolov5s-cls.pt --cfg models/yolov5s-senet-eca.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 50 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f6ca3fd-1804-4747-ade0-88432f96f68b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T16:15:44.040628Z",
     "iopub.status.busy": "2023-05-24T16:15:44.040112Z",
     "iopub.status.idle": "2023-05-24T16:16:04.403629Z",
     "shell.execute_reply": "2023-05-24T16:16:04.402103Z",
     "shell.execute_reply.started": "2023-05-24T16:15:44.040628Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp41/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro P5000, 16279MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-senet-eca summary: 167 layers, 25269837 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:08<00:00,  1.83it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984        0.97       0.996\n",
      "                drinking         182       0.973           1\n",
      "         hair and makeup         173       0.873       0.983\n",
      "     operating the radio         224       0.991           1\n",
      "         reaching behind         189       0.984           1\n",
      "            safe driving         205       0.976       0.995\n",
      "talking on the phone - left         218       0.995       0.995\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182       0.923       0.995\n",
      "          texting - left         209       0.976       0.995\n",
      "         texting - right         193        0.99           1\n",
      "Accuracy: 0.967558741569519 | Precision: 0.9686790108680725 | Recall: 0.967558741569519\n",
      "F1-Score: 0.9679148197174072 | Mean Average Precision: 0.9925311207771301\n",
      "Confusion Matrix:\n",
      "tensor([[177,   3,   0,   0,   0,   0,   0,   0,   0,   2],\n",
      "        [  7, 151,   1,   3,   3,   3,   4,   1,   0,   0],\n",
      "        [  0,   1, 222,   0,   0,   0,   0,   1,   0,   0],\n",
      "        [  0,   2,   0, 186,   0,   0,   0,   1,   0,   0],\n",
      "        [  1,   3,   0,   0, 200,   0,   0,   1,   0,   0],\n",
      "        [  0,   1,   0,   0,   0, 217,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0, 208,   0,   0,   1],\n",
      "        [  0,   2,   3,   2,   4,   0,   1, 168,   1,   1],\n",
      "        [  0,   0,   0,   0,   4,   1,   0,   0, 204,   0],\n",
      "        [  0,   0,   0,   0,   1,   0,   0,   1,   0, 191]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1924,    60, 17796,    60,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 3.2ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp89\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp41/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13547f70-1e2e-4b08-9d5b-2f3aad8b31f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T03:32:34.139121Z",
     "iopub.status.busy": "2023-05-26T03:32:34.138473Z",
     "iopub.status.idle": "2023-05-26T03:32:47.941952Z",
     "shell.execute_reply": "2023-05-26T03:32:47.940816Z",
     "shell.execute_reply.started": "2023-05-26T03:32:34.139092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp61/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 5000, 16125MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-senet-eca summary: 167 layers, 25269837 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:04<00:00,  3.44it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.972       0.996\n",
      "                drinking         182       0.973           1\n",
      "         hair and makeup         173       0.861       0.977\n",
      "     operating the radio         224       0.978           1\n",
      "         reaching behind         189           1           1\n",
      "            safe driving         205       0.971       0.985\n",
      "talking on the phone - left         218           1           1\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182       0.945           1\n",
      "          texting - left         209       0.986           1\n",
      "         texting - right         193       0.995           1\n",
      "Accuracy: 0.9702944755554199 | Precision: 0.9720188975334167 | Recall: 0.9702944755554199\n",
      "F1-Score: 0.9707605838775635 | Mean Average Precision: 0.9936867952346802\n",
      "Confusion Matrix:\n",
      "tensor([[177,   1,   0,   0,   1,   0,   0,   0,   0,   3],\n",
      "        [  4, 149,   3,   3,   3,   3,   4,   3,   0,   1],\n",
      "        [  0,   1, 219,   0,   2,   0,   0,   2,   0,   0],\n",
      "        [  0,   0,   0, 189,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,   2,   2,   0, 199,   0,   0,   1,   0,   0],\n",
      "        [  0,   0,   0,   0,   0, 218,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0, 208,   0,   0,   1],\n",
      "        [  0,   1,   2,   1,   3,   0,   1, 172,   0,   2],\n",
      "        [  1,   0,   1,   0,   0,   0,   0,   0, 206,   1],\n",
      "        [  0,   0,   0,   0,   0,   0,   1,   0,   0, 192]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1929,    55, 17801,    55,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 1.9ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp95\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp61/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cd1c4c-0509-4fbf-bfb4-005d2fd0f423",
   "metadata": {},
   "source": [
    "### Reduce on Plateau LRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de8c6562-9dc3-446f-aff2-4cf0c819475b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T14:33:40.494075Z",
     "iopub.status.busy": "2023-05-30T14:33:40.492933Z",
     "iopub.status.idle": "2023-05-30T16:17:45.227782Z",
     "shell.execute_reply": "2023-05-30T16:17:45.226469Z",
     "shell.execute_reply.started": "2023-05-30T14:33:40.494043Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train_noes_reduce-lrs: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-senet-eca.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=25, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp67, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "Command 'git fetch origin' timed out after 5 seconds\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro P5000, 16279MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1      2048  models.common.SENet                     [1024, 1024]                  \n",
      " 10                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 11                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-senet-eca summary: 227 layers, 25286541 parameters, 25286541 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 64 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp67\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 25 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/25     2.32G        2.23        2.07       0.247       0.777: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/25     2.59G        1.94        1.68       0.452       0.902: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/25     2.59G        1.49        1.25       0.682       0.977: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/25     2.59G        1.25        1.09       0.753       0.989: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/25     2.59G        1.09        0.92       0.844       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/25     2.59G       0.981        0.83       0.881       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/25     2.59G       0.908       0.792       0.904       0.992: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/25     2.59G       0.844        0.74       0.928       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/25     2.59G       0.796       0.719       0.934       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/25     2.59G        0.76       0.701       0.947       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     11/25     2.59G       0.727       0.679       0.951       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     12/25     2.59G       0.695       0.667        0.96       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     13/25     2.59G        0.68       0.656       0.964       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     14/25     2.59G       0.657       0.644       0.966       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     15/25     2.59G       0.646       0.641       0.971       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     16/25     2.59G       0.631        0.64       0.972       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     17/25     2.59G       0.616       0.639        0.97       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     18/25     2.59G       0.613       0.638        0.97       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     19/25     2.59G       0.596       0.632       0.972       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     20/25     2.59G       0.597       0.631       0.972       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     21/25     2.59G       0.588       0.629       0.973       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     22/25     2.59G       0.586        0.63       0.971       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     23/25     2.59G       0.576        0.63        0.97       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     24/25     2.59G       0.576        0.63       0.968       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     25/25     2.59G       0.567       0.631       0.968       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (1.715 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp67\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp67/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp67/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1\n",
      "Export:          python export.py --weights runs/train-cls/exp67/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp67/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train_noes_reduce-lrs.py --model yolov5s-cls.pt --cfg models/yolov5s-senet-eca.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 25 --img 256 --batch-size 32 --pretrained False --name exp67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62c5adc4-3cc9-42e7-887c-852f21f9cee5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T15:52:01.569054Z",
     "iopub.status.busy": "2023-05-31T15:52:01.567744Z",
     "iopub.status.idle": "2023-05-31T16:54:09.378183Z",
     "shell.execute_reply": "2023-05-31T16:54:09.377554Z",
     "shell.execute_reply.started": "2023-05-31T15:52:01.568982Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train_noes_reduce-lrs: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-senet-eca.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=50, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp68, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "Command 'git fetch origin' timed out after 5 seconds\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (NVIDIA RTX A4000, 16117MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1      2048  models.common.SENet                     [1024, 1024]                  \n",
      " 10                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 11                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-senet-eca summary: 227 layers, 25286541 parameters, 25286541 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 64 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp68\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 50 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/50      2.3G        2.31        2.35       0.104       0.508: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/50      2.8G         2.3         2.3       0.102       0.489: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/50      2.8G        2.17        2.18       0.265       0.737: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/50      2.8G        1.93        1.73       0.427        0.88: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/50      2.8G        1.73        1.97       0.347       0.868: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/50      2.8G        1.53        1.35       0.643       0.965: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/50      2.8G        1.38        1.17       0.707       0.975: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/50      2.8G        1.26        1.02       0.798       0.985: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/50      2.8G        1.15       0.945       0.827       0.991: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/50      2.8G        1.03        0.84       0.892       0.992: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     11/50      2.8G       0.949       0.784        0.91       0.993: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     12/50      2.8G       0.872       0.742       0.926       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     13/50      2.8G       0.821       0.711       0.941       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     14/50      2.8G       0.774       0.697       0.942       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     15/50      2.8G       0.745       0.686       0.949       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     16/50      2.8G       0.718       0.676       0.952       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     17/50      2.8G       0.694       0.668       0.956       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     18/50      2.8G       0.676       0.664       0.959       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     19/50      2.8G       0.657        0.66       0.959       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     20/50      2.8G        0.65        0.66       0.962       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     21/50      2.8G       0.631        0.66       0.961       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     22/50      2.8G       0.622       0.662        0.96       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     23/50      2.8G       0.614       0.665       0.961       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     24/50      2.8G       0.606        0.67       0.959       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     25/50      2.8G       0.552       0.671       0.957       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     26/50      2.8G       0.537       0.669       0.956       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     27/50      2.8G       0.532        0.67       0.955       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     28/50      2.8G       0.529       0.673       0.953       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     29/50      2.8G       0.525       0.678       0.952       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     30/50      2.8G       0.524       0.682       0.948       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     31/50      2.8G       0.523       0.685       0.945       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     32/50      2.8G       0.524       0.687       0.944       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     33/50      2.8G       0.523       0.687       0.945       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     34/50      2.8G       0.522       0.687       0.946       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     35/50      2.8G       0.522       0.684       0.946       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     36/50      2.8G       0.523       0.681       0.947       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     37/50      2.8G       0.522       0.677        0.95       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     38/50      2.8G       0.522       0.671        0.95       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     39/50      2.8G       0.522       0.666       0.951       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     40/50      2.8G       0.522        0.66       0.955       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     41/50      2.8G       0.522       0.654       0.957       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     42/50      2.8G       0.522       0.649        0.96       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     43/50      2.8G       0.522       0.643       0.961       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     44/50      2.8G       0.522       0.637       0.962       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     45/50      2.8G       0.523       0.632       0.963       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     46/50      2.8G       0.523       0.628       0.964       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     47/50      2.8G       0.523       0.623       0.966       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     48/50      2.8G       0.523       0.619       0.966       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     49/50      2.8G       0.522       0.615       0.967       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     50/50      2.8G       0.523       0.612       0.967       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (1.020 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp68\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp68/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp68/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1\n",
      "Export:          python export.py --weights runs/train-cls/exp68/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp68/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train_noes_reduce-lrs.py --model yolov5s-cls.pt --cfg models/yolov5s-senet-eca.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 50 --img 256 --batch-size 32 --pretrained False --name exp68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aaa90176-cb29-41cf-8855-1de39eabeefa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-30T16:34:01.940752Z",
     "iopub.status.busy": "2023-05-30T16:34:01.940213Z",
     "iopub.status.idle": "2023-05-30T16:34:26.259561Z",
     "shell.execute_reply": "2023-05-30T16:34:26.258489Z",
     "shell.execute_reply.started": "2023-05-30T16:34:01.940752Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp67/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro P5000, 16279MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-senet-eca summary: 167 layers, 25269837 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:09<00:00,  1.67it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.973       0.999\n",
      "                drinking         182       0.956           1\n",
      "         hair and makeup         173        0.85       0.994\n",
      "     operating the radio         224       0.991           1\n",
      "         reaching behind         189           1           1\n",
      "            safe driving         205       0.995           1\n",
      "talking on the phone - left         218           1           1\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182       0.945           1\n",
      "          texting - left         209       0.986       0.995\n",
      "         texting - right         193       0.984           1\n",
      "Accuracy: 0.9702320694923401 | Precision: 0.9727838039398193 | Recall: 0.9702320694923401\n",
      "F1-Score: 0.9709743857383728 | Mean Average Precision: 0.994371235370636\n",
      "Confusion Matrix:\n",
      "tensor([[174,   5,   1,   0,   0,   0,   0,   0,   0,   2],\n",
      "        [  7, 147,   3,   1,   5,   4,   5,   1,   0,   0],\n",
      "        [  0,   0, 222,   0,   1,   0,   0,   1,   0,   0],\n",
      "        [  0,   0,   0, 189,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,   0,   0,   0, 204,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0, 218,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0, 208,   0,   0,   1],\n",
      "        [  0,   1,   1,   3,   4,   0,   1, 172,   0,   0],\n",
      "        [  0,   0,   0,   0,   2,   1,   0,   0, 206,   0],\n",
      "        [  0,   0,   0,   0,   2,   0,   1,   0,   0, 190]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1930,    54, 17802,    54,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 3.5ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp67/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ceee7743-c538-4ce4-91af-6fc2d4d8cc24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:54:09.381274Z",
     "iopub.status.busy": "2023-05-31T16:54:09.381120Z",
     "iopub.status.idle": "2023-05-31T16:54:20.252814Z",
     "shell.execute_reply": "2023-05-31T16:54:20.252256Z",
     "shell.execute_reply.started": "2023-05-31T16:54:09.381255Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp68/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (NVIDIA RTX A4000, 16117MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-senet-eca summary: 167 layers, 25269837 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:04<00:00,  3.86it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.967       0.996\n",
      "                drinking         182       0.978           1\n",
      "         hair and makeup         173       0.803       0.965\n",
      "     operating the radio         224       0.978           1\n",
      "         reaching behind         189           1           1\n",
      "            safe driving         205       0.961           1\n",
      "talking on the phone - left         218       0.995           1\n",
      "talking on the phone - right         209        0.99           1\n",
      "    talking to passenger         182        0.94           1\n",
      "          texting - left         209           1           1\n",
      "         texting - right         193       0.995       0.995\n",
      "Accuracy: 0.9640367031097412 | Precision: 0.9652267098426819 | Recall: 0.9640367031097412\n",
      "F1-Score: 0.9639182686805725 | Mean Average Precision: 0.9911662340164185\n",
      "Confusion Matrix:\n",
      "tensor([[178,   2,   1,   1,   0,   0,   0,   0,   0,   0],\n",
      "        [ 13, 139,   1,   5,   3,   2,   4,   6,   0,   0],\n",
      "        [  0,   1, 219,   1,   2,   0,   0,   1,   0,   0],\n",
      "        [  0,   0,   0, 189,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,   3,   1,   0, 197,   0,   0,   3,   0,   0],\n",
      "        [  0,   0,   0,   1,   0, 217,   0,   0,   0,   0],\n",
      "        [  0,   1,   0,   0,   0,   0, 207,   0,   0,   1],\n",
      "        [  0,   1,   0,   1,   6,   0,   1, 171,   0,   2],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   0, 209,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   1,   0, 192]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1918,    66, 17790,    66,  1984], device='cuda:0')\n",
      "Speed: 0.0ms pre-process, 1.7ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    " !python classify/val.py --weights runs/train-cls/exp68/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1f09e6-95c3-4fec-a2c2-9cf24d0c6c1e",
   "metadata": {},
   "source": [
    "### Step LRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa5eb90e-3f1c-4b1a-8737-988a84c3fe0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T07:14:18.409278Z",
     "iopub.status.busy": "2023-05-23T07:14:18.408992Z",
     "iopub.status.idle": "2023-05-23T07:46:40.187855Z",
     "shell.execute_reply": "2023-05-23T07:46:40.187341Z",
     "shell.execute_reply.started": "2023-05-23T07:14:18.409253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train_noes_step-lrs: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-senet-eca.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=25, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 9 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (NVIDIA RTX A4000, 16117MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1      2048  models.common.SENet                     [1024, 1024]                  \n",
      " 10                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 11                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-senet-eca summary: 227 layers, 25286541 parameters, 25286541 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 64 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp43\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 25 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/25      2.3G        2.31        2.35       0.104       0.508: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/25      2.8G         2.3         2.3       0.102       0.489: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/25      2.8G        2.17        2.18       0.265       0.737: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/25      2.8G        1.93        1.73       0.427        0.88: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/25      2.8G        1.73        1.97       0.347       0.868: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/25      2.8G        1.53        1.35       0.643       0.965: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/25      2.8G        1.38        1.17       0.707       0.975: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/25      2.8G        1.26        1.02       0.798       0.985: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/25      2.8G        1.15       0.945       0.827       0.991: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/25      2.8G        1.03        0.84       0.892       0.992: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     11/25      2.8G       0.817       0.759       0.921       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     12/25      2.8G       0.757       0.732       0.934       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     13/25      2.8G       0.729       0.714       0.935       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     14/25      2.8G       0.703       0.696       0.943       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     15/25      2.8G       0.682       0.685       0.949       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     16/25      2.8G       0.664       0.675       0.952       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     17/25      2.8G       0.646       0.666       0.955       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     18/25      2.8G       0.635       0.659       0.955       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     19/25      2.8G       0.621       0.655       0.955       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     20/25      2.8G       0.609        0.65       0.957       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     21/25      2.8G       0.584       0.645       0.959       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     22/25      2.8G       0.578       0.642       0.961       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     23/25      2.8G       0.575        0.64       0.962       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     24/25      2.8G       0.572       0.638       0.962       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     25/25      2.8G       0.571       0.637       0.962       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (0.526 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp43\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp43/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp43/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1\n",
      "Export:          python export.py --weights runs/train-cls/exp43/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp43/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train_noes_step-lrs.py --model yolov5s-cls.pt --cfg models/yolov5s-senet-eca.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 25 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33833681-3c4e-4d78-9068-644c8d75c2ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T11:02:12.592551Z",
     "iopub.status.busy": "2023-05-31T11:02:12.591819Z",
     "iopub.status.idle": "2023-05-31T14:33:50.796114Z",
     "shell.execute_reply": "2023-05-31T14:33:50.795254Z",
     "shell.execute_reply.started": "2023-05-31T11:02:12.592522Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train_noes_step-lrs: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-senet-eca.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=50, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp64, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "remote: Enumerating objects: 3, done.\u001b[K\n",
      "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
      "remote: Compressing objects: 100% (3/3), done.\u001b[K\n",
      "remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (3/3), 2.05 KiB | 300.00 KiB/s, done.\n",
      "From https://github.com/ultralytics/yolov5\n",
      "   5733342..5eb7f7d  master     -> origin/master\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 12 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro P5000, 16279MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1      2048  models.common.SENet                     [1024, 1024]                  \n",
      " 10                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 11                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-senet-eca summary: 227 layers, 25286541 parameters, 25286541 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 64 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp64\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 50 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/50     2.32G        2.23        2.07       0.247       0.777: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/50     2.59G        1.94        1.68       0.452       0.902: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/50     2.59G        1.49        1.25       0.682       0.977: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/50     2.59G        1.25        1.09       0.753       0.989: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/50     2.59G        1.09        0.92       0.844       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/50     2.59G       0.981        0.83       0.881       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/50     2.59G       0.908       0.792       0.904       0.992: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/50     2.59G       0.844        0.74       0.928       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/50     2.59G       0.796       0.719       0.934       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/50     2.59G        0.76       0.701       0.947       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     11/50     2.59G       0.623       0.635       0.959       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     12/50     2.59G        0.59       0.624        0.96       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     13/50     2.59G       0.577       0.615       0.966       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     14/50     2.59G       0.567       0.608       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     15/50     2.59G        0.56       0.602       0.967       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     16/50     2.59G       0.552       0.599       0.966       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     17/50     2.59G       0.547       0.595        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     18/50     2.59G       0.542       0.593        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     19/50     2.59G       0.538        0.59        0.97       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     20/50     2.59G       0.536       0.589       0.971       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     21/50     2.59G       0.527       0.586       0.972       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     22/50     2.59G       0.524       0.584       0.973       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     23/50     2.59G       0.523       0.583       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     24/50     2.59G       0.522       0.582       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     25/50     2.59G       0.521       0.582       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     26/50     2.59G       0.521       0.581       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     27/50     2.59G        0.52       0.581       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     28/50     2.59G        0.52       0.581       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     29/50     2.59G        0.52       0.581       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     30/50     2.59G       0.519        0.58       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     31/50     2.59G       0.518        0.58       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     32/50     2.59G       0.518        0.58       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     33/50     2.59G       0.518        0.58       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     34/50     2.59G       0.518        0.58       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     35/50     2.59G       0.518       0.579       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     36/50     2.59G       0.518       0.579       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     37/50     2.59G       0.518       0.579       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     38/50     2.59G       0.518       0.579       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     39/50     2.59G       0.517       0.579       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     40/50     2.59G       0.518       0.578       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     41/50     2.59G       0.517       0.578       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     42/50     2.59G       0.518       0.578       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     43/50     2.59G       0.517       0.578       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     44/50     2.59G       0.517       0.578       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     45/50     2.59G       0.518       0.578       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     46/50     2.59G       0.517       0.577       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     47/50     2.59G       0.517       0.577       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     48/50     2.59G       0.518       0.577       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     49/50     2.59G       0.517       0.577       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     50/50     2.59G       0.517       0.577       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (3.512 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp64\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp64/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp64/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1\n",
      "Export:          python export.py --weights runs/train-cls/exp64/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp64/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train_noes_step-lrs.py --model yolov5s-cls.pt --cfg models/yolov5s-senet-eca.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 50 --img 256 --batch-size 32 --pretrained False --name exp64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "954cc128-c9c7-4cac-8e8b-534ea832cf8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T16:15:03.685355Z",
     "iopub.status.busy": "2023-05-24T16:15:03.684989Z",
     "iopub.status.idle": "2023-05-24T16:15:23.874675Z",
     "shell.execute_reply": "2023-05-24T16:15:23.873757Z",
     "shell.execute_reply.started": "2023-05-24T16:15:03.685351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp43/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro P5000, 16279MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-senet-eca summary: 167 layers, 25269837 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:08<00:00,  1.80it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.962       0.997\n",
      "                drinking         182       0.951           1\n",
      "         hair and makeup         173       0.821       0.988\n",
      "     operating the radio         224       0.978           1\n",
      "         reaching behind         189       0.979           1\n",
      "            safe driving         205       0.966       0.995\n",
      "talking on the phone - left         218       0.995       0.995\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182       0.929           1\n",
      "          texting - left         209        0.99       0.995\n",
      "         texting - right         193        0.99           1\n",
      "Accuracy: 0.9592994451522827 | Precision: 0.9606636762619019 | Recall: 0.9592994451522827\n",
      "F1-Score: 0.9595714807510376 | Mean Average Precision: 0.987584114074707\n",
      "Confusion Matrix:\n",
      "tensor([[173,   6,   0,   0,   1,   0,   0,   0,   0,   2],\n",
      "        [  9, 142,   3,   4,   4,   1,   5,   5,   0,   0],\n",
      "        [  0,   0, 219,   2,   2,   0,   0,   1,   0,   0],\n",
      "        [  0,   0,   3, 185,   0,   0,   0,   1,   0,   0],\n",
      "        [  1,   2,   0,   0, 198,   0,   0,   3,   0,   1],\n",
      "        [  0,   1,   0,   0,   0, 217,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0, 208,   0,   0,   1],\n",
      "        [  0,   2,   0,   1,   9,   0,   0, 169,   0,   1],\n",
      "        [  1,   0,   0,   0,   1,   0,   0,   0, 207,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   1,   1, 191]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1909,    75, 17781,    75,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 3.8ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp87\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp43/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a11ebec4-7e9e-491f-a00d-538d68e2fe65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T15:51:23.991238Z",
     "iopub.status.busy": "2023-05-31T15:51:23.990545Z",
     "iopub.status.idle": "2023-05-31T15:51:37.188535Z",
     "shell.execute_reply": "2023-05-31T15:51:37.187703Z",
     "shell.execute_reply.started": "2023-05-31T15:51:23.991214Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp64/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (NVIDIA RTX A4000, 16117MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-senet-eca summary: 167 layers, 25269837 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:05<00:00,  3.18it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.975       0.998\n",
      "                drinking         182       0.973           1\n",
      "         hair and makeup         173       0.867       0.988\n",
      "     operating the radio         224       0.987           1\n",
      "         reaching behind         189       0.995           1\n",
      "            safe driving         205       0.976       0.995\n",
      "talking on the phone - left         218           1           1\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182       0.956           1\n",
      "          texting - left         209        0.99           1\n",
      "         texting - right         193       0.995           1\n",
      "Accuracy: 0.973301351070404 | Precision: 0.974641740322113 | Recall: 0.973301351070404\n",
      "F1-Score: 0.9736784100532532 | Mean Average Precision: 0.9954727292060852\n",
      "Confusion Matrix:\n",
      "tensor([[177,   3,   0,   0,   0,   0,   0,   0,   0,   2],\n",
      "        [  8, 150,   1,   0,   1,   5,   5,   2,   0,   1],\n",
      "        [  0,   0, 221,   0,   2,   0,   0,   1,   0,   0],\n",
      "        [  0,   0,   1, 188,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,   3,   0,   0, 200,   0,   0,   0,   1,   0],\n",
      "        [  0,   0,   0,   0,   0, 218,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0, 208,   0,   0,   1],\n",
      "        [  0,   1,   0,   3,   2,   0,   1, 174,   0,   1],\n",
      "        [  0,   0,   0,   0,   2,   0,   0,   0, 207,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   1,   0,   0, 192]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1935,    49, 17807,    49,  1984], device='cuda:0')\n",
      "Speed: 0.0ms pre-process, 1.9ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp8\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp64/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaee3e0-8e81-4f71-bf2b-2375e90c232b",
   "metadata": {},
   "source": [
    "### Linear LRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dd2bf29-8176-452b-b448-7031637166c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T13:45:20.369061Z",
     "iopub.status.busy": "2023-05-23T13:45:20.368406Z",
     "iopub.status.idle": "2023-05-23T14:17:07.876578Z",
     "shell.execute_reply": "2023-05-23T14:17:07.875962Z",
     "shell.execute_reply.started": "2023-05-23T13:45:20.369036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train_noes_linear-lrs: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-senet-eca.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=25, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 10 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (NVIDIA RTX A4000, 16117MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1      2048  models.common.SENet                     [1024, 1024]                  \n",
      " 10                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 11                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-senet-eca summary: 227 layers, 25286541 parameters, 25286541 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 64 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp45\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 25 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/25      2.3G        2.17        1.91       0.337       0.855: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/25      2.8G         1.5        1.13        0.74       0.983: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/25      2.8G        1.09       0.911       0.848       0.993: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/25      2.8G       0.917       0.823       0.894       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/25      2.8G       0.834        0.75       0.917       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/25      2.8G       0.782        0.74       0.921       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/25      2.8G       0.751       0.692       0.949       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/25      2.8G       0.724       0.677       0.947       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/25      2.8G        0.71       0.652       0.961       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/25      2.8G       0.695       0.638       0.962       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     11/25      2.8G       0.686       0.622       0.968           1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     12/25      2.8G       0.683       0.626       0.972       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     13/25      2.8G       0.677       0.628       0.969       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     14/25      2.8G       0.669       0.625       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     15/25      2.8G       0.663        0.62       0.974       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     16/25      2.8G       0.659       0.623       0.972       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     17/25      2.8G       0.644       0.617       0.976       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     18/25      2.8G       0.648       0.616       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     19/25      2.8G       0.642       0.615       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     20/25      2.8G       0.635       0.613       0.976       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     21/25      2.8G       0.627       0.615       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     22/25      2.8G       0.628       0.619       0.972       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     23/25      2.8G       0.616       0.619       0.972       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     24/25      2.8G        0.62        0.62       0.972       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     25/25      2.8G       0.606       0.619       0.972       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (0.516 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp45\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp45/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp45/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1\n",
      "Export:          python export.py --weights runs/train-cls/exp45/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp45/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train_noes_linear-lrs.py --model yolov5s-cls.pt --cfg models/yolov5s-senet-eca.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 25 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15c67615-5ad3-44f2-ad1e-1171b3df6fbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T16:54:20.254207Z",
     "iopub.status.busy": "2023-05-31T16:54:20.254019Z",
     "iopub.status.idle": "2023-05-31T17:56:39.925591Z",
     "shell.execute_reply": "2023-05-31T17:56:39.924846Z",
     "shell.execute_reply.started": "2023-05-31T16:54:20.254189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train_noes_linear-lrs: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-senet-eca.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=50, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp65, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 12 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (NVIDIA RTX A4000, 16117MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1      2048  models.common.SENet                     [1024, 1024]                  \n",
      " 10                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 11                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-senet-eca summary: 227 layers, 25286541 parameters, 25286541 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 64 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp65\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 50 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/50      2.3G        2.17        1.91       0.337       0.855: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/50      2.8G         1.5        1.16       0.726       0.973: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/50      2.8G        1.08       0.974       0.824       0.989: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/50      2.8G       0.907       0.797       0.902       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/50      2.8G       0.816       0.747       0.921       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/50      2.8G       0.762       0.728       0.922       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/50      2.8G       0.732       0.681       0.948       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/50      2.8G       0.703       0.671       0.954       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/50      2.8G       0.689       0.642       0.964       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/50      2.8G       0.674       0.623       0.968       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     11/50      2.8G       0.664       0.623       0.971       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     12/50      2.8G       0.659       0.621       0.967       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     13/50      2.8G       0.653       0.622        0.97       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     14/50      2.8G       0.645       0.627       0.969       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     15/50      2.8G       0.642       0.621       0.972       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     16/50      2.8G       0.627       0.615       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     17/50      2.8G       0.628       0.614       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     18/50      2.8G       0.627       0.614       0.976       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     19/50      2.8G       0.614       0.614       0.975       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     20/50      2.8G       0.617       0.612       0.976       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     21/50      2.8G       0.607        0.61       0.975       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     22/50      2.8G       0.607       0.612       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     23/50      2.8G       0.601       0.612       0.974       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     24/50      2.8G         0.6       0.612       0.973       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     25/50      2.8G       0.596       0.613       0.974       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     26/50      2.8G       0.592       0.613       0.973       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     27/50      2.8G       0.593       0.615       0.972       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     28/50      2.8G       0.587       0.616       0.973       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     29/50      2.8G       0.583       0.618       0.972       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     30/50      2.8G       0.582        0.62        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     31/50      2.8G       0.584       0.623       0.965       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     32/50      2.8G       0.577       0.629       0.961       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     33/50      2.8G       0.577        0.64       0.955       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     34/50      2.8G       0.573       0.654        0.95       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     35/50      2.8G       0.575        0.68       0.936       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     36/50      2.8G       0.571       0.717       0.918       0.993: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     37/50      2.8G       0.571       0.767       0.887       0.993: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     38/50      2.8G        0.57       0.833       0.848        0.99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     39/50      2.8G       0.561       0.916       0.808       0.988: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     40/50      2.8G        0.57        1.01       0.768       0.986: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     41/50      2.8G       0.552        1.11        0.72       0.984: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     42/50      2.8G        0.57        1.23       0.672        0.98: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     43/50      2.8G       0.557        1.35       0.614       0.972: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     44/50      2.8G       0.557        1.47       0.559       0.963: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     45/50      2.8G       0.562        1.57       0.516       0.943: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     46/50      2.8G       0.551        1.67       0.474        0.93: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     47/50      2.8G        0.56        1.76       0.434       0.909: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     48/50      2.8G       0.552        1.83       0.406       0.892: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     49/50      2.8G       0.561         1.9       0.382       0.879: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     50/50      2.8G       0.549        1.95       0.366       0.867: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (1.025 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp65\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp65/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp65/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1\n",
      "Export:          python export.py --weights runs/train-cls/exp65/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp65/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train_noes_linear-lrs.py --model yolov5s-cls.pt --cfg models/yolov5s-senet-eca.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 50 --img 256 --batch-size 32 --pretrained False --name exp65"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0f58911-fd93-4119-9662-ad5d342f3d7c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T16:14:44.163994Z",
     "iopub.status.busy": "2023-05-24T16:14:44.162297Z",
     "iopub.status.idle": "2023-05-24T16:15:03.682984Z",
     "shell.execute_reply": "2023-05-24T16:15:03.681656Z",
     "shell.execute_reply.started": "2023-05-24T16:14:44.163929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp45/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro P5000, 16279MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-senet-eca summary: 167 layers, 25269837 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:08<00:00,  1.79it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.976       0.998\n",
      "                drinking         182       0.984       0.995\n",
      "         hair and makeup         173       0.867       0.988\n",
      "     operating the radio         224       0.987           1\n",
      "         reaching behind         189           1           1\n",
      "            safe driving         205        0.99           1\n",
      "talking on the phone - left         218           1           1\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182        0.94           1\n",
      "          texting - left         209       0.995           1\n",
      "         texting - right         193       0.984           1\n",
      "Accuracy: 0.9741866588592529 | Precision: 0.9762696623802185 | Recall: 0.9741866588592529\n",
      "F1-Score: 0.9747470021247864 | Mean Average Precision: 0.9965195059776306\n",
      "Confusion Matrix:\n",
      "tensor([[179,   1,   0,   0,   1,   0,   1,   0,   0,   0],\n",
      "        [  5, 150,   2,   2,   1,   2,   6,   5,   0,   0],\n",
      "        [  0,   0, 221,   1,   1,   0,   0,   1,   0,   0],\n",
      "        [  0,   0,   0, 189,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,   0,   1,   0, 203,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0, 218,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0, 208,   0,   0,   1],\n",
      "        [  0,   2,   0,   3,   5,   0,   1, 171,   0,   0],\n",
      "        [  0,   0,   0,   0,   1,   0,   0,   0, 208,   0],\n",
      "        [  0,   0,   0,   0,   2,   0,   1,   0,   0, 190]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1937,    47, 17809,    47,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 3.4ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp86\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp45/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a35bc1a-c9ee-4928-96a0-9355ddb39519",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T17:56:39.926647Z",
     "iopub.status.busy": "2023-05-31T17:56:39.926466Z",
     "iopub.status.idle": "2023-05-31T17:56:51.095842Z",
     "shell.execute_reply": "2023-05-31T17:56:51.095082Z",
     "shell.execute_reply.started": "2023-05-31T17:56:39.926630Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp65/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (NVIDIA RTX A4000, 16117MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-senet-eca summary: 167 layers, 25269837 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:04<00:00,  3.78it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.976       0.999\n",
      "                drinking         182       0.967           1\n",
      "         hair and makeup         173       0.873       0.994\n",
      "     operating the radio         224       0.982           1\n",
      "         reaching behind         189           1           1\n",
      "            safe driving         205        0.99           1\n",
      "talking on the phone - left         218           1           1\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182       0.956       0.995\n",
      "          texting - left         209        0.99           1\n",
      "         texting - right         193        0.99           1\n",
      "Accuracy: 0.9743579030036926 | Precision: 0.9759639501571655 | Recall: 0.9743579030036926\n",
      "F1-Score: 0.9747892022132874 | Mean Average Precision: 0.9959150552749634\n",
      "Confusion Matrix:\n",
      "tensor([[176,   3,   0,   0,   1,   0,   0,   0,   0,   2],\n",
      "        [  4, 151,   1,   2,   3,   3,   4,   5,   0,   0],\n",
      "        [  0,   0, 220,   1,   2,   0,   0,   1,   0,   0],\n",
      "        [  0,   0,   0, 189,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,   0,   0,   0, 203,   0,   0,   1,   0,   0],\n",
      "        [  0,   0,   0,   0,   0, 218,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0, 208,   0,   0,   1],\n",
      "        [  0,   1,   1,   3,   2,   0,   1, 174,   0,   0],\n",
      "        [  0,   0,   0,   0,   2,   0,   0,   0, 207,   0],\n",
      "        [  0,   0,   0,   0,   1,   0,   1,   0,   0, 191]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1937,    47, 17809,    47,  1984], device='cuda:0')\n",
      "Speed: 0.0ms pre-process, 1.6ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp10\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp65/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b07500-e6c0-4d3c-858c-03e9e1af6690",
   "metadata": {},
   "source": [
    "### Exponential LRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07af39c1-21ec-461d-895a-bd1d0c181a32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T14:17:07.877743Z",
     "iopub.status.busy": "2023-05-23T14:17:07.877554Z",
     "iopub.status.idle": "2023-05-23T14:48:58.336533Z",
     "shell.execute_reply": "2023-05-23T14:48:58.335878Z",
     "shell.execute_reply.started": "2023-05-23T14:17:07.877724Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train_noes_exp-lrs: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-senet-eca.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=25, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 10 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (NVIDIA RTX A4000, 16117MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1      2048  models.common.SENet                     [1024, 1024]                  \n",
      " 10                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 11                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-senet-eca summary: 227 layers, 25286541 parameters, 25286541 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 64 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp46\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 25 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/25      2.3G        2.31        2.35       0.104       0.508: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/25      2.8G        2.23        2.16       0.213       0.722: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/25      2.8G        1.96         1.7       0.441       0.912: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/25      2.8G        1.63         1.5       0.554        0.93: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/25      2.8G         1.4        1.17       0.704       0.984: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/25      2.8G        1.21        1.03       0.787       0.987: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/25      2.8G        1.08       0.895       0.848        0.99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/25      2.8G       0.965       0.838       0.882       0.991: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/25      2.8G       0.873       0.754        0.91       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/25      2.8G         0.8       0.717       0.931       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     11/25      2.8G        0.75       0.692       0.935       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     12/25      2.8G       0.706       0.679       0.939       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     13/25      2.8G       0.672       0.662       0.949       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     14/25      2.8G       0.645        0.65       0.956       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     15/25      2.8G       0.625       0.638       0.959       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     16/25      2.8G       0.609       0.631        0.96       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     17/25      2.8G       0.583       0.624        0.96       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     18/25      2.8G       0.571       0.619       0.963       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     19/25      2.8G       0.566       0.616       0.963       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     20/25      2.8G       0.557       0.612       0.964       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     21/25      2.8G       0.545        0.61       0.964       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     22/25      2.8G       0.541       0.607       0.965       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     23/25      2.8G       0.535       0.606       0.965       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     24/25      2.8G       0.531       0.606       0.963       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     25/25      2.8G       0.529       0.605       0.962       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (0.517 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp46\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp46/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp46/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1\n",
      "Export:          python export.py --weights runs/train-cls/exp46/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp46/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train_noes_exp-lrs.py --model yolov5s-cls.pt --cfg models/yolov5s-senet-eca.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 25 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3921974-de94-4f91-8fae-a76eb7fbc8bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T17:56:51.098320Z",
     "iopub.status.busy": "2023-05-31T17:56:51.098098Z",
     "iopub.status.idle": "2023-05-31T18:59:06.333602Z",
     "shell.execute_reply": "2023-05-31T18:59:06.332779Z",
     "shell.execute_reply.started": "2023-05-31T17:56:51.098300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train_noes_exp-lrs: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-senet-eca.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=50, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp66, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 12 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (NVIDIA RTX A4000, 16117MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1      2048  models.common.SENet                     [1024, 1024]                  \n",
      " 10                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 11                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-senet-eca summary: 227 layers, 25286541 parameters, 25286541 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 64 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp66\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 50 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "      1/50      2.3G        2.31        2.35       0.104       0.508: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      2/50      2.8G        2.23        2.16       0.213       0.722: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      3/50      2.8G        1.96         1.7       0.441       0.912: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      4/50      2.8G        1.63         1.5       0.554        0.93: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      5/50      2.8G         1.4        1.17       0.704       0.984: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      6/50      2.8G        1.21        1.03       0.787       0.987: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      7/50      2.8G        1.08       0.895       0.848        0.99: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      8/50      2.8G       0.965       0.838       0.882       0.991: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "      9/50      2.8G       0.873       0.754        0.91       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     10/50      2.8G         0.8       0.717       0.931       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     11/50      2.8G        0.75       0.692       0.935       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     12/50      2.8G       0.706       0.679       0.939       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     13/50      2.8G       0.672       0.662       0.949       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     14/50      2.8G       0.645        0.65       0.956       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     15/50      2.8G       0.625       0.638       0.959       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     16/50      2.8G       0.609       0.631        0.96       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     17/50      2.8G       0.583       0.624        0.96       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     18/50      2.8G       0.571       0.619       0.963       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     19/50      2.8G       0.566       0.616       0.963       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     20/50      2.8G       0.557       0.612       0.964       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     21/50      2.8G       0.545        0.61       0.964       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     22/50      2.8G       0.541       0.607       0.965       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     23/50      2.8G       0.535       0.606       0.965       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     24/50      2.8G       0.531       0.606       0.963       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     25/50      2.8G       0.529       0.605       0.962       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     26/50      2.8G       0.525       0.605       0.961       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     27/50      2.8G        0.52       0.606        0.96       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     28/50      2.8G       0.521       0.607        0.96       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     29/50      2.8G       0.519       0.608        0.96       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     30/50      2.8G       0.515        0.61       0.959       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     31/50      2.8G       0.513       0.613       0.956       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     32/50      2.8G       0.514       0.616       0.954       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     33/50      2.8G       0.512       0.619       0.954       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     34/50      2.8G       0.511       0.623       0.953       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     35/50      2.8G       0.509       0.628       0.953       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     36/50      2.8G       0.509       0.634       0.949       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     37/50      2.8G       0.509        0.64       0.946       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     38/50      2.8G       0.508       0.647       0.942       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     39/50      2.8G       0.507       0.656        0.94       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     40/50      2.8G       0.507       0.665        0.94       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     41/50      2.8G       0.507       0.674       0.934       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     42/50      2.8G       0.506       0.686        0.93       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     43/50      2.8G       0.506       0.698       0.924       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     44/50      2.8G       0.506        0.71       0.919       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     45/50      2.8G       0.506       0.723       0.907       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     46/50      2.8G       0.505       0.735       0.901       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     47/50      2.8G       0.505       0.748       0.894       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     48/50      2.8G       0.505        0.76       0.887       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     49/50      2.8G       0.505       0.771       0.885       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     50/50      2.8G       0.505        0.78       0.882       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "\n",
      "Training complete (1.024 hours)\n",
      "Results saved to \u001b[1mruns/train-cls/exp66\u001b[0m\n",
      "Predict:         python classify/predict.py --weights runs/train-cls/exp66/weights/best.pt --source im.jpg\n",
      "Validate:        python classify/val.py --weights runs/train-cls/exp66/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1\n",
      "Export:          python export.py --weights runs/train-cls/exp66/weights/best.pt --include onnx\n",
      "PyTorch Hub:     model = torch.hub.load('ultralytics/yolov5', 'custom', 'runs/train-cls/exp66/weights/best.pt')\n",
      "Visualize:       https://netron.app\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python classify/train_noes_exp-lrs.py --model yolov5s-cls.pt --cfg models/yolov5s-senet-eca.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 50 --img 256 --batch-size 32 --pretrained False --name exp66"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "867d70c8-cea3-427b-9f09-dd06bd106b2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T16:13:53.612977Z",
     "iopub.status.busy": "2023-05-24T16:13:53.612535Z",
     "iopub.status.idle": "2023-05-24T16:14:13.858297Z",
     "shell.execute_reply": "2023-05-24T16:14:13.856580Z",
     "shell.execute_reply.started": "2023-05-24T16:13:53.612934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp46/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro P5000, 16279MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-senet-eca summary: 167 layers, 25269837 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:08<00:00,  1.78it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.965       0.999\n",
      "                drinking         182       0.956           1\n",
      "         hair and makeup         173       0.827           1\n",
      "     operating the radio         224       0.991       0.996\n",
      "         reaching behind         189       0.974           1\n",
      "            safe driving         205       0.985           1\n",
      "talking on the phone - left         218       0.995           1\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182       0.923           1\n",
      "          texting - left         209       0.986           1\n",
      "         texting - right         193        0.99           1\n",
      "Accuracy: 0.9621604084968567 | Precision: 0.9647538661956787 | Recall: 0.9621604084968567\n",
      "F1-Score: 0.9628784656524658 | Mean Average Precision: 0.9903896450996399\n",
      "Confusion Matrix:\n",
      "tensor([[174,   4,   0,   0,   0,   0,   1,   0,   0,   3],\n",
      "        [  7, 143,   5,   1,   4,   0,   8,   4,   1,   0],\n",
      "        [  0,   0, 222,   1,   0,   0,   0,   1,   0,   0],\n",
      "        [  0,   3,   1, 184,   0,   0,   1,   0,   0,   0],\n",
      "        [  1,   0,   2,   0, 202,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   1, 217,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0, 208,   0,   0,   1],\n",
      "        [  0,   3,   0,   1,   9,   0,   0, 168,   0,   1],\n",
      "        [  1,   0,   0,   0,   2,   0,   0,   0, 206,   0],\n",
      "        [  0,   0,   0,   0,   1,   0,   1,   0,   0, 191]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1915,    69, 17787,    69,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 3.3ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp85\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp46/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28744c10-ab6e-4fd1-aee0-eb570ad200b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-31T18:59:06.336007Z",
     "iopub.status.busy": "2023-05-31T18:59:06.335810Z",
     "iopub.status.idle": "2023-05-31T18:59:17.629048Z",
     "shell.execute_reply": "2023-05-31T18:59:17.628255Z",
     "shell.execute_reply.started": "2023-05-31T18:59:06.335988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp66/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (NVIDIA RTX A4000, 16117MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-senet-eca summary: 167 layers, 25269837 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:04<00:00,  3.69it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.965       0.999\n",
      "                drinking         182       0.956           1\n",
      "         hair and makeup         173       0.827           1\n",
      "     operating the radio         224       0.991       0.996\n",
      "         reaching behind         189       0.974           1\n",
      "            safe driving         205       0.985           1\n",
      "talking on the phone - left         218       0.995           1\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182       0.923           1\n",
      "          texting - left         209       0.986           1\n",
      "         texting - right         193        0.99           1\n",
      "Accuracy: 0.9621604084968567 | Precision: 0.9647538661956787 | Recall: 0.9621604084968567\n",
      "F1-Score: 0.9628784656524658 | Mean Average Precision: 0.9903966188430786\n",
      "Confusion Matrix:\n",
      "tensor([[174,   4,   0,   0,   0,   0,   1,   0,   0,   3],\n",
      "        [  7, 143,   5,   1,   4,   0,   8,   4,   1,   0],\n",
      "        [  0,   0, 222,   1,   0,   0,   0,   1,   0,   0],\n",
      "        [  0,   3,   1, 184,   0,   0,   1,   0,   0,   0],\n",
      "        [  1,   0,   2,   0, 202,   0,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   1, 217,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0, 208,   0,   0,   1],\n",
      "        [  0,   3,   0,   1,   9,   0,   0, 168,   0,   1],\n",
      "        [  1,   0,   0,   0,   2,   0,   0,   0, 206,   0],\n",
      "        [  0,   0,   0,   0,   1,   0,   1,   0,   0, 191]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1915,    69, 17787,    69,  1984], device='cuda:0')\n",
      "Speed: 0.0ms pre-process, 1.8ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp11\u001b[0m\n"
     ]
    }
   ],
   "source": [
    " !python classify/val.py --weights runs/train-cls/exp66/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e32569-3336-4e8a-8b04-ca211eab8e8d",
   "metadata": {},
   "source": [
    "## With Early Stopping\n",
    "\n",
    "### Lambda LRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58c50027-7c46-444f-b56a-c3a9d47185e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-23T16:02:54.727029Z",
     "iopub.status.busy": "2023-05-23T16:02:54.726732Z",
     "iopub.status.idle": "2023-05-23T16:38:28.846990Z",
     "shell.execute_reply": "2023-05-23T16:38:28.846252Z",
     "shell.execute_reply.started": "2023-05-23T16:02:54.727006Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train_es_lambda-lrs: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-senet-eca.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=100, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 10 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (NVIDIA RTX A4000, 16117MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1      2048  models.common.SENet                     [1024, 1024]                  \n",
      " 10                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 11                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-senet-eca summary: 227 layers, 25286541 parameters, 25286541 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 64 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp51\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 100 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "     1/100      2.3G        2.31        2.35       0.104       0.508: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     2/100      2.8G         2.3        2.29       0.125       0.597: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     3/100      2.8G        2.16        2.02       0.276       0.786: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     4/100      2.8G        1.88        1.53       0.523       0.935: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     5/100      2.8G        1.52        1.32       0.621       0.956: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     6/100      2.8G        1.31        1.06       0.753       0.989: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     7/100      2.8G        1.17       0.978       0.804       0.993: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     8/100      2.8G        1.04       0.886       0.838       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     9/100      2.8G       0.938       0.783       0.907       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    10/100      2.8G       0.865       0.746       0.925       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    11/100      2.8G       0.804        0.72       0.933       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    12/100      2.8G       0.758       0.709       0.945       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    13/100      2.8G       0.729       0.686        0.95       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    14/100      2.8G       0.697       0.674       0.956       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    15/100      2.8G        0.67       0.665       0.957           1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    16/100      2.8G       0.655       0.655       0.961           1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    17/100      2.8G       0.634       0.652       0.965           1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    18/100      2.8G       0.625        0.65       0.967           1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    19/100      2.8G       0.612       0.646       0.968       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    20/100      2.8G         0.6       0.641       0.969           1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    21/100      2.8G       0.592       0.638       0.968       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    22/100      2.8G       0.585       0.637       0.969       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    23/100      2.8G       0.582       0.638       0.971       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    24/100      2.8G       0.571       0.637       0.969       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    25/100      2.8G       0.568       0.637       0.968       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    26/100      2.8G       0.571       0.637       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    27/100      2.8G       0.559       0.637       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    28/100      2.8G        0.56       0.638       0.967       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "Early stopping: validation loss did not improve for 3 epochs\n"
     ]
    }
   ],
   "source": [
    "!python classify/train_es_lambda-lrs.py --model yolov5s-cls.pt --cfg models/yolov5s-senet-eca.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 100 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4daa5c41-567b-41a1-aa34-d5d0f7f8b29d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T16:12:51.084802Z",
     "iopub.status.busy": "2023-05-24T16:12:51.084324Z",
     "iopub.status.idle": "2023-05-24T16:13:21.296886Z",
     "shell.execute_reply": "2023-05-24T16:13:21.294526Z",
     "shell.execute_reply.started": "2023-05-24T16:12:51.084802Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp51/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro P5000, 16279MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-senet-eca summary: 167 layers, 25269837 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:12<00:00,  1.29it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984        0.97       0.999\n",
      "                drinking         182       0.962           1\n",
      "         hair and makeup         173       0.844       0.988\n",
      "     operating the radio         224       0.991           1\n",
      "         reaching behind         189       0.995           1\n",
      "            safe driving         205       0.976           1\n",
      "talking on the phone - left         218       0.991           1\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182       0.956           1\n",
      "          texting - left         209       0.976           1\n",
      "         texting - right         193       0.995           1\n",
      "Accuracy: 0.9679839611053467 | Precision: 0.9694781303405762 | Recall: 0.9679839611053467\n",
      "F1-Score: 0.9683139324188232 | Mean Average Precision: 0.9918044209480286\n",
      "Confusion Matrix:\n",
      "tensor([[175,   4,   0,   0,   0,   0,   0,   0,   0,   3],\n",
      "        [  9, 146,   3,   0,   3,   2,   5,   5,   0,   0],\n",
      "        [  0,   0, 222,   0,   1,   0,   0,   1,   0,   0],\n",
      "        [  0,   0,   1, 188,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,   2,   0,   0, 200,   0,   0,   2,   0,   0],\n",
      "        [  0,   1,   1,   0,   0, 216,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0, 208,   0,   0,   1],\n",
      "        [  0,   0,   1,   2,   4,   0,   1, 174,   0,   0],\n",
      "        [  0,   0,   0,   0,   4,   0,   0,   1, 204,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   1,   0, 192]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1925,    59, 17797,    59,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 4.5ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp84\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp51/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31bb22e-c135-4de5-a82d-b18e5d3fb984",
   "metadata": {},
   "source": [
    "### Step LRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "881a5f3b-2e87-4297-acb3-585e9d369b19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T16:49:52.636460Z",
     "iopub.status.busy": "2023-05-24T16:49:52.635775Z",
     "iopub.status.idle": "2023-05-24T19:05:15.657654Z",
     "shell.execute_reply": "2023-05-24T19:05:15.656935Z",
     "shell.execute_reply.started": "2023-05-24T16:49:52.636428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train_es_step-lrs: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-senet-eca.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=100, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 10 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 5000, 16125MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1      2048  models.common.SENet                     [1024, 1024]                  \n",
      " 10                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 11                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-senet-eca summary: 227 layers, 25286541 parameters, 25286541 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 64 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp55\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 100 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "     1/100     2.45G        2.27        2.09       0.206       0.757: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     2/100     2.92G        1.99        1.91        0.33       0.834: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     3/100     2.92G        1.53         1.3       0.666       0.975: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     4/100     2.92G         1.3        1.07       0.762       0.988: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     5/100     2.92G        1.15        1.11       0.753       0.983: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     6/100     2.92G        1.04       0.864       0.873       0.991: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     7/100     2.92G       0.957       0.856       0.859       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     8/100     2.92G       0.882       0.778       0.907       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     9/100     2.92G       0.832       0.736       0.926       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    10/100     2.92G       0.784         0.7       0.942       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    11/100     2.92G       0.638        0.65       0.956       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    12/100     2.92G       0.603       0.637       0.961       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    13/100     2.92G       0.588       0.627       0.961       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    14/100     2.92G       0.576       0.621       0.964       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    15/100     2.92G       0.567       0.616       0.965       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    16/100     2.92G        0.56       0.613       0.967       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    17/100     2.92G       0.551       0.609       0.967       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    18/100     2.92G       0.545       0.607       0.967       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    19/100     2.92G       0.542       0.604       0.967       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    20/100     2.92G       0.539       0.602       0.967       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    21/100     2.92G       0.528         0.6       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    22/100     2.92G       0.525       0.598       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    23/100     2.92G       0.524       0.597       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    24/100     2.92G       0.523       0.596       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    25/100     2.92G       0.522       0.596       0.967       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    26/100     2.92G       0.522       0.595       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    27/100     2.92G       0.521       0.595       0.967       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    28/100     2.92G       0.521       0.594       0.967       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    29/100     2.92G        0.52       0.594       0.967       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    30/100     2.92G        0.52       0.594       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    31/100     2.92G       0.519       0.594       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    32/100     2.92G       0.519       0.593       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    33/100     2.92G       0.519       0.593       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    34/100     2.92G       0.518       0.593       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    35/100     2.92G       0.518       0.593       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    36/100     2.92G       0.518       0.592       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    37/100     2.92G       0.518       0.592       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    38/100     2.92G       0.518       0.592       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    39/100     2.92G       0.518       0.592       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    40/100     2.92G       0.518       0.592       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    41/100     2.92G       0.518       0.591       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    42/100     2.92G       0.518       0.591       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    43/100     2.92G       0.518       0.591       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    44/100     2.92G       0.518       0.591       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    45/100     2.92G       0.518       0.591       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    46/100     2.92G       0.518       0.591       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    47/100     2.92G       0.518        0.59       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    48/100     2.92G       0.518        0.59       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    49/100     2.92G       0.518        0.59       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    50/100     2.92G       0.518        0.59       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    51/100     2.92G       0.518        0.59       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    52/100     2.92G       0.518        0.59       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    53/100     2.92G       0.518        0.59       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    54/100     2.92G       0.518        0.59       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    55/100     2.92G       0.518        0.59       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    56/100     2.92G       0.518        0.59       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    57/100     2.92G       0.518        0.59       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    58/100     2.92G       0.518        0.59        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    59/100     2.92G       0.518        0.59        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    60/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    61/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    62/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    63/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    64/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    65/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    66/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    67/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    68/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    69/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    70/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    71/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    72/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    73/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    74/100     2.92G       0.517       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    75/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    76/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    77/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    78/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    79/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    80/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    81/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    82/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    83/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    84/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    85/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    86/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    87/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    88/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    89/100     2.92G       0.518       0.589        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "Early stopping: validation loss did not improve for 3 epochs\n"
     ]
    }
   ],
   "source": [
    "!python classify/train_es_step-lrs.py --model yolov5s-cls.pt --cfg models/yolov5s-senet-eca.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 100 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11ee0360-8403-42bc-a1df-1ef9dac92e73",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T02:01:20.621893Z",
     "iopub.status.busy": "2023-05-26T02:01:20.621605Z",
     "iopub.status.idle": "2023-05-26T02:01:34.740914Z",
     "shell.execute_reply": "2023-05-26T02:01:34.739765Z",
     "shell.execute_reply.started": "2023-05-26T02:01:20.621869Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp55/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 5000, 16125MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-senet-eca summary: 167 layers, 25269837 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:04<00:00,  3.26it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984        0.97       0.998\n",
      "                drinking         182       0.984           1\n",
      "         hair and makeup         173       0.867       0.988\n",
      "     operating the radio         224       0.982           1\n",
      "         reaching behind         189       0.968           1\n",
      "            safe driving         205       0.951       0.995\n",
      "talking on the phone - left         218       0.995           1\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182       0.962           1\n",
      "          texting - left         209       0.986           1\n",
      "         texting - right         193       0.995           1\n",
      "Accuracy: 0.9684816002845764 | Precision: 0.9696764349937439 | Recall: 0.9684816002845764\n",
      "F1-Score: 0.9688297510147095 | Mean Average Precision: 0.9909278750419617\n",
      "Confusion Matrix:\n",
      "tensor([[179,   1,   1,   0,   0,   0,   0,   0,   0,   1],\n",
      "        [  7, 150,   4,   1,   1,   4,   4,   1,   0,   1],\n",
      "        [  0,   1, 220,   0,   1,   0,   0,   2,   0,   0],\n",
      "        [  0,   2,   2, 183,   0,   0,   0,   2,   0,   0],\n",
      "        [  1,   3,   3,   0, 195,   0,   0,   2,   1,   0],\n",
      "        [  0,   1,   0,   0,   0, 217,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0, 208,   0,   0,   1],\n",
      "        [  0,   1,   0,   0,   3,   0,   1, 175,   0,   2],\n",
      "        [  1,   1,   1,   0,   0,   0,   0,   0, 206,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   1,   0,   0, 192]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1925,    59, 17797,    59,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 1.7ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp90\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp55/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927f57f3-d818-46a3-a420-c1bb1d70e109",
   "metadata": {},
   "source": [
    "### Linear LRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85078e32-8203-4654-9c4e-6a663ed7ddbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T19:05:15.660637Z",
     "iopub.status.busy": "2023-05-24T19:05:15.660362Z",
     "iopub.status.idle": "2023-05-24T19:41:57.682252Z",
     "shell.execute_reply": "2023-05-24T19:41:57.681177Z",
     "shell.execute_reply.started": "2023-05-24T19:05:15.660609Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train_es_linear-lrs: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-senet-eca.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=100, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 10 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 5000, 16125MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1      2048  models.common.SENet                     [1024, 1024]                  \n",
      " 10                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 11                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-senet-eca summary: 227 layers, 25286541 parameters, 25286541 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 64 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp56\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 100 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "     1/100     2.45G        2.15        1.79       0.416       0.869: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     2/100     2.92G        1.47        1.11        0.74       0.987: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     3/100     2.92G        1.07       0.952       0.828       0.987: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     4/100     2.92G       0.902         0.8       0.893       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     5/100     2.92G       0.809       0.753       0.912       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     6/100     2.92G       0.752       0.735       0.925       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     7/100     2.92G       0.726       0.674       0.949       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     8/100     2.92G       0.694       0.656       0.953       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     9/100     2.92G       0.679       0.659       0.953       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    10/100     2.92G       0.661       0.641       0.959       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    11/100     2.92G       0.646       0.626       0.968       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    12/100     2.92G       0.645       0.629       0.964       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    13/100     2.92G       0.629       0.627       0.967       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    14/100     2.92G       0.625       0.619       0.971       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    15/100     2.92G       0.622       0.619       0.969       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    16/100     2.92G       0.611       0.612       0.969       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    17/100     2.92G       0.603       0.611       0.972       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    18/100     2.92G       0.603       0.609       0.973       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    19/100     2.92G         0.6       0.609       0.971       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    20/100     2.92G       0.599       0.609       0.972       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    21/100     2.92G       0.584       0.607       0.972       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    22/100     2.92G        0.59       0.609       0.971       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    23/100     2.92G       0.588       0.609       0.971       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    24/100     2.92G       0.586       0.611       0.971       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "Early stopping: validation loss did not improve for 3 epochs\n"
     ]
    }
   ],
   "source": [
    "!python classify/train_es_linear-lrs.py --model yolov5s-cls.pt --cfg models/yolov5s-senet-eca.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 100 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a642132b-e418-4c14-8938-031dfd35f797",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T02:01:34.743135Z",
     "iopub.status.busy": "2023-05-26T02:01:34.742313Z",
     "iopub.status.idle": "2023-05-26T02:01:49.004466Z",
     "shell.execute_reply": "2023-05-26T02:01:49.003408Z",
     "shell.execute_reply.started": "2023-05-26T02:01:34.743097Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp56/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 5000, 16125MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-senet-eca summary: 167 layers, 25269837 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:04<00:00,  3.25it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.973       0.997\n",
      "                drinking         182       0.973           1\n",
      "         hair and makeup         173       0.873       0.983\n",
      "     operating the radio         224       0.987           1\n",
      "         reaching behind         189       0.984           1\n",
      "            safe driving         205       0.971       0.995\n",
      "talking on the phone - left         218       0.995           1\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182       0.951       0.995\n",
      "          texting - left         209        0.99           1\n",
      "         texting - right         193       0.995           1\n",
      "Accuracy: 0.9713252782821655 | Precision: 0.9737074375152588 | Recall: 0.9713252782821655\n",
      "F1-Score: 0.972135603427887 | Mean Average Precision: 0.9944654703140259\n",
      "Confusion Matrix:\n",
      "tensor([[177,   2,   0,   0,   0,   0,   1,   0,   0,   2],\n",
      "        [  4, 151,   3,   0,   3,   3,   7,   2,   0,   0],\n",
      "        [  0,   0, 221,   0,   2,   0,   0,   1,   0,   0],\n",
      "        [  0,   0,   2, 186,   0,   0,   0,   1,   0,   0],\n",
      "        [  1,   1,   3,   0, 199,   0,   0,   1,   0,   0],\n",
      "        [  0,   0,   0,   0,   1, 217,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0, 208,   0,   0,   1],\n",
      "        [  1,   1,   1,   1,   4,   0,   1, 173,   0,   0],\n",
      "        [  0,   0,   0,   0,   2,   0,   0,   0, 207,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   1,   0,   0, 192]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1931,    53, 17803,    53,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 1.6ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp91\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp56/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e23af6c-0329-4409-ab12-a194109c5e9a",
   "metadata": {},
   "source": [
    "### Cosine LRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2d9b71d-0855-4dbd-860e-f16f71fffe8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T19:41:57.687246Z",
     "iopub.status.busy": "2023-05-24T19:41:57.686503Z",
     "iopub.status.idle": "2023-05-24T20:20:01.262264Z",
     "shell.execute_reply": "2023-05-24T20:20:01.261472Z",
     "shell.execute_reply.started": "2023-05-24T19:41:57.687201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train_es_cos-lrs: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-senet-eca.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=100, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 10 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 5000, 16125MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1      2048  models.common.SENet                     [1024, 1024]                  \n",
      " 10                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 11                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-senet-eca summary: 227 layers, 25286541 parameters, 25286541 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 64 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp57\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 100 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "     1/100     2.45G        2.27        2.09       0.206       0.757: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     2/100     2.92G        1.99        1.68       0.486       0.914: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     3/100     2.92G         1.5        1.48       0.523       0.961: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     4/100     2.92G        1.27        1.13       0.728       0.989: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     5/100     2.92G        1.14        1.08       0.776       0.978: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     6/100     2.92G        1.04       0.917       0.853       0.991: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     7/100     2.92G       0.965       0.829       0.879       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     8/100     2.92G       0.891       0.762       0.911       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     9/100     2.92G       0.838       0.732       0.923       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    10/100     2.92G       0.789       0.696       0.946       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    11/100     2.92G       0.758       0.693       0.947       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    12/100     2.92G       0.723       0.678        0.95       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    13/100     2.92G       0.703        0.66       0.962       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    14/100     2.92G       0.677       0.654        0.96       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    15/100     2.92G       0.658       0.645       0.963       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    16/100     2.92G       0.646       0.641       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    17/100     2.92G        0.63       0.638        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    18/100     2.92G       0.619       0.637       0.971       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    19/100     2.92G       0.606       0.634        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    20/100     2.92G       0.605       0.633       0.971       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    21/100     2.92G       0.593        0.63       0.971       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    22/100     2.92G       0.586       0.628        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    23/100     2.92G       0.581       0.627       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    24/100     2.92G       0.578       0.628       0.967       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    25/100     2.92G       0.567       0.629       0.967       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "Early stopping: validation loss did not improve for 3 epochs\n"
     ]
    }
   ],
   "source": [
    "!python classify/train_es_cos-lrs.py --model yolov5s-cls.pt --cfg models/yolov5s-senet-eca.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 100 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c65910e-4401-4f39-a251-c2fc400ef039",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T02:01:49.006874Z",
     "iopub.status.busy": "2023-05-26T02:01:49.006346Z",
     "iopub.status.idle": "2023-05-26T02:02:03.756053Z",
     "shell.execute_reply": "2023-05-26T02:02:03.755308Z",
     "shell.execute_reply.started": "2023-05-26T02:01:49.006847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp57/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 5000, 16125MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-senet-eca summary: 167 layers, 25269837 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:05<00:00,  3.11it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.971       0.999\n",
      "                drinking         182       0.973           1\n",
      "         hair and makeup         173       0.855           1\n",
      "     operating the radio         224       0.982           1\n",
      "         reaching behind         189       0.995           1\n",
      "            safe driving         205       0.976           1\n",
      "talking on the phone - left         218       0.995           1\n",
      "talking on the phone - right         209        0.99           1\n",
      "    talking to passenger         182        0.94       0.995\n",
      "          texting - left         209        0.99       0.995\n",
      "         texting - right         193       0.995           1\n",
      "Accuracy: 0.9691133499145508 | Precision: 0.9719515442848206 | Recall: 0.9691133499145508\n",
      "F1-Score: 0.9699509143829346 | Mean Average Precision: 0.9934923052787781\n",
      "Confusion Matrix:\n",
      "tensor([[177,   1,   0,   0,   1,   0,   1,   0,   0,   2],\n",
      "        [  6, 148,   3,   1,   5,   3,   5,   1,   0,   1],\n",
      "        [  0,   0, 220,   1,   2,   0,   0,   1,   0,   0],\n",
      "        [  0,   1,   0, 188,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,   0,   3,   0, 200,   0,   0,   1,   0,   0],\n",
      "        [  0,   0,   0,   0,   1, 217,   0,   0,   0,   0],\n",
      "        [  0,   0,   1,   0,   0,   0, 207,   0,   0,   1],\n",
      "        [  0,   1,   2,   2,   5,   0,   1, 171,   0,   0],\n",
      "        [  0,   0,   1,   0,   1,   0,   0,   0, 207,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   1,   0,   0, 192]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1927,    57, 17799,    57,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 1.7ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp92\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp57/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d70b828-7161-44c2-9536-67c8a4dddef1",
   "metadata": {},
   "source": [
    "### ReduceOnPlateau LRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "405958a2-bcca-4f23-bcd0-e3e0e5187f00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-24T20:20:01.264208Z",
     "iopub.status.busy": "2023-05-24T20:20:01.263943Z",
     "iopub.status.idle": "2023-05-24T20:56:49.249825Z",
     "shell.execute_reply": "2023-05-24T20:56:49.248900Z",
     "shell.execute_reply.started": "2023-05-24T20:20:01.264178Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train_es_reduce-lrs: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-senet-eca.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=100, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 10 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 5000, 16125MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1      2048  models.common.SENet                     [1024, 1024]                  \n",
      " 10                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 11                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-senet-eca summary: 227 layers, 25286541 parameters, 25286541 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 64 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp58\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 100 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "     1/100     2.45G        2.27        2.09       0.206       0.757: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     2/100     2.92G        1.99        1.91        0.33       0.834: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     3/100     2.92G        1.53         1.3       0.666       0.975: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     4/100     2.92G         1.3        1.07       0.762       0.988: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     5/100     2.92G        1.15        1.11       0.753       0.983: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     6/100     2.92G        1.04       0.864       0.873       0.991: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     7/100     2.92G       0.957       0.856       0.859       0.994: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     8/100     2.92G       0.882       0.778       0.907       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     9/100     2.92G       0.832       0.736       0.926       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    10/100     2.92G       0.784         0.7       0.942       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    11/100     2.92G       0.747       0.694        0.94       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    12/100     2.92G       0.715       0.681       0.949       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    13/100     2.92G       0.696       0.664       0.957       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    14/100     2.92G       0.671        0.66       0.957       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    15/100     2.92G       0.656       0.655       0.959       0.997: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    16/100     2.92G       0.645        0.65       0.964       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    17/100     2.92G       0.627       0.644       0.966       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    18/100     2.92G       0.621       0.643       0.966       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    19/100     2.92G       0.609       0.639       0.965       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    20/100     2.92G       0.601       0.638       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    21/100     2.92G       0.597       0.636       0.971       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    22/100     2.92G       0.588       0.634       0.971       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    23/100     2.92G       0.587       0.635        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    24/100     2.92G        0.58       0.636        0.97       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "Early stopping: validation loss did not improve for 3 epochs\n"
     ]
    }
   ],
   "source": [
    "!python classify/train_es_reduce-lrs.py --model yolov5s-cls.pt --cfg models/yolov5s-senet-eca.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 100 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa561224-e407-4ba5-aeba-356fc1fe7af6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T02:02:17.418456Z",
     "iopub.status.busy": "2023-05-26T02:02:17.418214Z",
     "iopub.status.idle": "2023-05-26T02:02:31.303671Z",
     "shell.execute_reply": "2023-05-26T02:02:31.302873Z",
     "shell.execute_reply.started": "2023-05-26T02:02:17.418433Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp58/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 5000, 16125MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-senet-eca summary: 167 layers, 25269837 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:04<00:00,  3.38it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984       0.971       0.998\n",
      "                drinking         182       0.973           1\n",
      "         hair and makeup         173       0.855       0.983\n",
      "     operating the radio         224       0.978           1\n",
      "         reaching behind         189       0.979           1\n",
      "            safe driving         205       0.976           1\n",
      "talking on the phone - left         218           1           1\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182       0.956           1\n",
      "          texting - left         209       0.986           1\n",
      "         texting - right         193        0.99           1\n",
      "Accuracy: 0.9686685800552368 | Precision: 0.9709451198577881 | Recall: 0.9686685800552368\n",
      "F1-Score: 0.9693556427955627 | Mean Average Precision: 0.9923754930496216\n",
      "Confusion Matrix:\n",
      "tensor([[177,   1,   0,   0,   1,   0,   2,   0,   0,   1],\n",
      "        [  7, 148,   4,   0,   3,   3,   4,   3,   1,   0],\n",
      "        [  0,   1, 219,   0,   3,   0,   0,   1,   0,   0],\n",
      "        [  0,   1,   2, 185,   0,   0,   0,   1,   0,   0],\n",
      "        [  1,   2,   1,   0, 200,   0,   0,   1,   0,   0],\n",
      "        [  0,   0,   0,   0,   0, 218,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0, 208,   0,   0,   1],\n",
      "        [  0,   0,   0,   1,   6,   0,   1, 174,   0,   0],\n",
      "        [  0,   0,   1,   0,   1,   0,   0,   0, 206,   1],\n",
      "        [  0,   0,   0,   0,   1,   0,   1,   0,   0, 191]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1926,    58, 17798,    58,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 2.0ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp94\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp58/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab29285-e368-4cc6-81ff-fea8b01bdc1f",
   "metadata": {},
   "source": [
    "### Exponential LRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0d0c3c3-a876-445b-819e-b928527d86a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T01:19:09.751848Z",
     "iopub.status.busy": "2023-05-26T01:19:09.751508Z",
     "iopub.status.idle": "2023-05-26T02:01:20.619554Z",
     "shell.execute_reply": "2023-05-26T02:01:20.618394Z",
     "shell.execute_reply.started": "2023-05-26T01:19:09.751819Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: WARNING ‚ö†Ô∏è wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: (30 second timeout) \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B disabled due to login timeout.\n",
      "\u001b[34m\u001b[1mclassify/train_es_exp-lrs: \u001b[0mmodel=yolov5s-cls.pt, cfg=models/yolov5s-senet-eca.yaml, data=/notebooks/datasets/Driver-Distraction-Detection-1/, epochs=100, batch_size=32, imgsz=256, nosave=False, cache=None, device=, workers=8, project=runs/train-cls, name=exp, exist_ok=False, pretrained=False, optimizer=Adam, lr0=0.001, decay=5e-05, label_smoothing=0.1, cutoff=None, dropout=None, verbose=False, seed=0, local_rank=-1\n",
      "\u001b[34m\u001b[1mgithub: \u001b[0m‚ö†Ô∏è YOLOv5 is out of date by 10 commits. Use 'git pull' or 'git clone https://github.com/ultralytics/yolov5' to update.\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 5000, 16125MiB)\n",
      "\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train-cls', view at http://localhost:6006/\n",
      "\u001b[34m\u001b[1malbumentations: \u001b[0m‚ö†Ô∏è not found, install with `pip install albumentations` (recommended)\n",
      "\n",
      "                 from  n    params  module                                  arguments                     \n",
      "  0                -1  1      7040  models.common.Conv                      [3, 64, 6, 2, 2]              \n",
      "  1                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               \n",
      "  2                -1  3    156928  models.common.C3                        [128, 128, 3]                 \n",
      "  3                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              \n",
      "  4                -1  6   1118208  models.common.C3                        [256, 256, 6]                 \n",
      "  5                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              \n",
      "  6                -1  9   6433792  models.common.C3                        [512, 512, 9]                 \n",
      "  7                -1  1   4720640  models.common.Conv                      [512, 1024, 3, 2]             \n",
      "  8                -1  3   9971712  models.common.C3                        [1024, 1024, 3]               \n",
      "  9                -1  1      2048  models.common.SENet                     [1024, 1024]                  \n",
      " 10                -1  1         3  models.common.ECA                       [1024, 1024]                  \n",
      " 11                -1  1   1326090  models.common.Classify                  [1024, 10]                    \n",
      "YOLOv5s-senet-eca summary: 227 layers, 25286541 parameters, 25286541 gradients\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001) with parameter groups 60 weight(decay=0.0), 64 weight(decay=5e-05), 61 bias\n",
      "Image sizes 256 train, 256 test\n",
      "Using 7 dataloader workers\n",
      "Logging results to \u001b[1mruns/train-cls/exp59\u001b[0m\n",
      "Starting yolov5s-cls.pt training on /notebooks/datasets/Driver-Distraction-Detection-1 dataset with 10 classes for 100 epochs...\n",
      "\n",
      "     Epoch   GPU_mem  train_loss    val_loss    top1_acc    top5_acc\n",
      "     1/100     2.45G        2.27        2.09       0.206       0.757: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     2/100     2.92G        2.01        1.64       0.498       0.901: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     3/100     2.92G        1.55        1.39       0.602       0.963: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     4/100     2.92G        1.27        1.13       0.736       0.989: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     5/100     2.92G        1.11       0.977        0.82       0.987: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     6/100     2.92G           1       0.886       0.852       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     7/100     2.92G       0.911        0.81       0.895       0.995: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     8/100     2.92G       0.831        0.75       0.919       0.996: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "     9/100     2.92G       0.772       0.714       0.935       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    10/100     2.92G       0.718        0.68        0.95       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    11/100     2.92G       0.679       0.661       0.958       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    12/100     2.92G       0.648       0.649       0.957       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    13/100     2.92G       0.625       0.638        0.96       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    14/100     2.92G       0.601       0.627       0.962       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    15/100     2.92G       0.589       0.619       0.966       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    16/100     2.92G       0.573       0.612       0.969       0.999: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    17/100     2.92G       0.563       0.607       0.967       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    18/100     2.92G       0.554       0.603       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    19/100     2.92G       0.548       0.601        0.97       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    20/100     2.92G       0.542       0.598       0.971       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    21/100     2.92G       0.536       0.597       0.969       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    22/100     2.92G       0.533       0.596       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    23/100     2.92G       0.529       0.596       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    24/100     2.92G       0.526       0.595       0.967       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    25/100     2.92G       0.524       0.595       0.967       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    26/100     2.92G       0.521       0.595       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "    27/100     2.92G        0.52       0.596       0.968       0.998: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà\n",
      "Early stopping: validation loss did not improve for 3 epochs\n"
     ]
    }
   ],
   "source": [
    "!python classify/train_es_exp-lrs.py --model yolov5s-cls.pt --cfg models/yolov5s-senet-eca.yaml --data /notebooks/datasets/Driver-Distraction-Detection-1/ --epochs 100 --img 256 --batch-size 32 --pretrained False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf4f668b-02e0-4f4f-86a2-aa93ed6ec11a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-26T02:02:03.758085Z",
     "iopub.status.busy": "2023-05-26T02:02:03.757145Z",
     "iopub.status.idle": "2023-05-26T02:02:17.416928Z",
     "shell.execute_reply": "2023-05-26T02:02:17.415958Z",
     "shell.execute_reply.started": "2023-05-26T02:02:03.758053Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mclassify/val: \u001b[0mdata=/notebooks/datasets/Driver-Distraction-Detection-1, weights=['runs/train-cls/exp59/weights/best.pt'], batch_size=128, imgsz=256, device=, workers=8, verbose=True, project=runs/val-cls, name=exp, exist_ok=False, half=False, dnn=False\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m /notebooks/requirements.txt not found, check failed.\n",
      "YOLOv5 üöÄ v7.0-162-gc3e4e94 Python-3.9.16 torch-1.12.1+cu116 CUDA:0 (Quadro RTX 5000, 16125MiB)\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s-senet-eca summary: 167 layers, 25269837 parameters, 0 gradients\n",
      "validating: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 16/16 [00:04<00:00,  3.32it/s]\n",
      "                   Class      Images    top1_acc    top5_acc\n",
      "                     all        1984        0.97       0.998\n",
      "                drinking         182       0.973           1\n",
      "         hair and makeup         173       0.867       0.988\n",
      "     operating the radio         224       0.978           1\n",
      "         reaching behind         189       0.968           1\n",
      "            safe driving         205       0.976       0.995\n",
      "talking on the phone - left         218       0.995           1\n",
      "talking on the phone - right         209       0.995           1\n",
      "    talking to passenger         182       0.951       0.995\n",
      "          texting - left         209       0.986           1\n",
      "         texting - right         193       0.995           1\n",
      "Accuracy: 0.9682763814926147 | Precision: 0.9695661067962646 | Recall: 0.9682763814926147\n",
      "F1-Score: 0.968646764755249 | Mean Average Precision: 0.993137776851654\n",
      "Confusion Matrix:\n",
      "tensor([[177,   3,   0,   0,   1,   0,   0,   0,   0,   1],\n",
      "        [  7, 150,   2,   1,   1,   3,   3,   5,   0,   1],\n",
      "        [  0,   1, 219,   0,   3,   0,   0,   1,   0,   0],\n",
      "        [  0,   0,   2, 183,   1,   0,   0,   3,   0,   0],\n",
      "        [  1,   2,   1,   0, 200,   0,   0,   1,   0,   0],\n",
      "        [  0,   0,   0,   0,   1, 217,   0,   0,   0,   0],\n",
      "        [  0,   0,   0,   0,   0,   0, 208,   0,   0,   1],\n",
      "        [  0,   1,   1,   2,   3,   0,   1, 173,   0,   1],\n",
      "        [  0,   0,   0,   0,   1,   2,   0,   0, 206,   0],\n",
      "        [  0,   0,   0,   0,   0,   0,   0,   1,   0, 192]], device='cuda:0')\n",
      "Stat Score [TP, FP, TN, FN, Support (TP + FN): tensor([ 1925,    59, 17797,    59,  1984], device='cuda:0')\n",
      "Speed: 0.1ms pre-process, 1.8ms inference, 0.0ms post-process per image at shape (1, 3, 256, 256)\n",
      "Results saved to \u001b[1mruns/val-cls/exp93\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python classify/val.py --weights runs/train-cls/exp59/weights/best.pt --data /notebooks/datasets/Driver-Distraction-Detection-1 --img 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19b03bba-e7d9-443f-9802-3dfcc54e9655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-01T01:26:35.367029Z",
     "iopub.status.busy": "2023-06-01T01:26:35.366223Z",
     "iopub.status.idle": "2023-06-01T01:27:21.761218Z",
     "shell.execute_reply": "2023-06-01T01:27:21.760324Z",
     "shell.execute_reply.started": "2023-06-01T01:26:35.366997Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks\n",
      "updating: fyp.ipynb (deflated 91%)\n"
     ]
    }
   ],
   "source": [
    "%cd /notebooks\n",
    "!zip -r fyp.zip fyp.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
